人工知能
人工知能の導入
東京農工大学工学部知能情報システム工学科
藤田桂英
(katfuji@cc.tuat.ac.jp)
1
教員の紹介
藤田桂英（Katsuhide Fujita)、教授
居室: 10号館403、Email: katfuji@cc.tuat.ac.jp
²
東京農工大学大学院グローバルイノベーション研究院/工学研究院
²
東京農工大学大学院工学府知能情報システム工学専攻
²
東京農工大学工学部知能情報システム工学科
2008. 3
名古屋工業大学情報工学科卒
2010. 3     同 大学院産業戦略工学専攻 博士前期課程修了
2011. 6     同 大学院情報工学専攻 博士後期課程修了（1年3ヶ月早期修了） 
2010. 4 - 2011. 9
日本学術振興会特別研究員(DC1 -> PD)
2010. 6 - 2011. 5
マサチューセッツ工科大学Visiting Student
2011. 10 - 2012. 11 東京大学大学院工学系研究科
2012. 12 -
東京農工大学工学研究院准教授
2023. 10 -
東京農工大学グローバルイノベーション研究院教授
専門: 人工知能、マルチエージェントシステム、テキストマイニング
2
人工知能とは？
² “そうぞう（創造、想像）”の産物？
² 人間の味方？脅威？
² 我々の目に見えるもの？見えないもの？
² 夢物語？すでに実現している？
3
人工知能の講義の概要と目的
² 概要
³ 知能処理アルゴリズムや人工知能システムを構築するための
知識やアルゴリズムを紹介
³ 人工知能の基礎から比較的最近のトピックまで
³ 探索、ゲーム、論理による導出原理や知識表現
³ Web Intelligence、マルチエージェントシステム
² 目的
³ 人工知能に関連する一通りの知識を持つ
³ 人工知能に関連するシステムを構築する能力を身につける
² 他の講義との関連
³ アルゴリズム序論、アルゴリズム論→マスターしていると仮定
³ 関数プログラミング、オブジェクト指向プログラミング
→人工知能で学んだことを実現する手段
4
講義予定
開講日
内容
第1回
4/8(月)
人工知能の導入
第2回
4/15(月)
基本的な探索（幅優先・深さ優先など）
第3回
4/22(月)
最適経路探索（A*アルゴリズムなど）
第4回
5/13(月)
メタヒューリスティック探索（HC, SA, GA）
第5回
5/20(月)
ゲームの理論
第6回
5/27(月)
確率と不確実性
第7回
6/3(月)
確率的生成モデルとナイーブベイズ
6/10(月)
休講
第8回
6/17(月)
強化学習
第9回
6/24(月)
記号論理
第10回
7/1(月)
導出原理
第11回
7/8(月)
Webインテリジェンス
第12回
7/15(月・祝)
エージェント（1）
第13回
7/22(月)
エージェント（2）
第14回
7/29(月)
期末テスト*詳細は後日連絡
評価方法
² 期末テスト（対面）: 90%
³ 持ち込みあり（ただし、ノートPC、タブレットなど
通信機能があるものは不可）
³ 単位が欲しい人は必ず受験
² 出席調査（平常点）: 10%
³ 毎回Google Classroomのテスト機能により調査
³ 講義中に演習問題が出た場合は答案を提出
6
Sirius LMSの活用
² Sirius LMSを活用
³ Siriusで履修登録をしてください
² 講義の連絡や予定が更新されます
（大事な内容は学科掲示板にも投稿します）
² 講義のスライドがダウンロードできます
² 出席確認や演習問題の提出にも使用
² そのほか講義に関する重要な情報も告知
7
参考書
² 「人工知能学辞典」共立出版, 2005.
² 松本他、知能システム入門、コロナ社
² S.J.Russell (著), P.Norvig (著), 古川康一 (翻訳)
エージェントアプローチ人工知能 第2版共立出版
² 谷口忠大、イラストで学ぶ人工知能概論第2版、
KS情報科学専門書
8
9
人工知能の導入と歴史
人工知能とは何か？
² 「人工知能の基礎」（小林 一郎）
³ 人の知能、つまり、人が行なう知的作業は、推論、
記憶、認識、理解、学習、創造といった現実世界に
適応するための能力を指す。人工の「知能」とは，
人の「知能」のある部分を機械に行わせることに
よって創られる。
² デジタル大辞泉《Artificial Intelligence》
³ コンピューターで、記憶・推論・判断・学習など、人間
の知的機能を代行できるようにモデル化されたソフト
ウエア・システム。AI。
10
空想の中での人工知能
² 「2001年宇宙の旅」HAL9000
² 「マトリックス」 エージェントスミス
² 「スターウォーズ」 R2D2
² 「鉄腕アトム」アトム他
² 「ドラえもん」ドラえもん他
² 「キテレツ大百科」コロスケ
など多数
11
学問としての人工知能
² AI = Artificial Intelligence (人工知能) 
³ 第二次世界大戦の頃から始まった比較的新しい分野
³ 多くの情報工学の研究がAI研究として扱われている
http://ja.wikipedia.org/wiki/Category:⼈⼯知能
12
人工知能は実現できているか？
² 結論: まだできていない
³ 「人間のように考えるコンピュータ」はで
きていない
² 将来人工知能はできるか?     
→できるだろう
³ 人間の脳= 電気回路の原理と同じ
³ 脳にはシナプスがあり，電圧が一定
以上ならば，神経伝達物質が放出
→次のシナプスに電気信号つながる
13
人工知能とロボット
² ロボットの脳にあたるのが人工知能
³ ロボット研究者の一部が人工知能も研究
³ 人工知能の研究対象はロボットの脳だけではない
⼈⼯知能
ロボット
人工知能
ロボット
ゲームAI
情報推薦
自然言語
アーム
歩行
パワードスーツ
対話ロボット
お掃除ロボット
14
世間から見た人工知能
~人工知能のレベル~
² 世の中でよく聞く「人工知能」という言葉
「人工知能を搭載した製品を発売」
「人工知能を使って解析します」
² レベル1: 単純な制御= 人工知能？
³ 人がいるところを集中的に温めるエアコン
² レベル2: 古典的な人工知能
³ お掃除ロボット，質問応答，ゲーム（囲碁，将棋など）
² レベル3: 汎用性をもった人工知能
³ 自動的に大切な情報を判断できる
³ 人工知能同士が協力できる
15
人工知能の歴史まとめ
² 人工知能の懐胎(1943~1955) 
² 人工知能の誕生(1956) ⇒ダートマスワークショップ
² 古き良き人工知能(1957~1974)
² 現実からの反撃(1974~1980)
² 人工知能の産業化(1980~1987)
² 再度、冬の時代へ(1987~2000) 
² 新しい人工知能モデルの出現(1992~現在）
² 大規模データの利用(2010 ~ 現在)
² 人工知能ブーム再来（2015 ~ 現在)
歴史的によき時代と冬の時代が繰り返されている
16
黎明期1950年代から
² 1956年：ダートマス会議(Dartmouth Conference)
³ J. McCarthy が Artificial Intelligence （人工知能）という言葉
を使ったことから始まったと言われる。
² それまでの歴史
³ 1945年：ENIAC（弾道計算用の世界初の大型計算機）
³ 1950年：チューリング(A. M. Turing) “Computer Machinery 
and Intelligence” チューリングテストの提案
³ 1950年：シャノン (C. Shannon) “Automatic Chess Player”
³ 1958年：マッカーシー(J. MacCarthy) LISP リスト処理言語
³ 1956年：ダートマス会議
17
チューリングテスト
² J.Searle 「中国人の部屋」で批判
² 「機能主義」をとるかどうかが論点となる
wikipedia より
18
人工知能の歴史 (1980年頃まで)
² 1950-1960年代
³ 1969年マッカーシーとヘイズのSome Philosophical 
Problems from the Standpoint of Artificial Intelligence 
→フレーム問題
³ このころの希望に満ち溢れていた時代
= GOFAI (Good Old Fashioned AI:古き良きAI)
² 1970年代：エキスパートシステム
³ 現実世界における膨大な知識をシステムが持っている
→現実世界の様々な問題を解決できる
² 1972年：ウィノグラードのNatural Language Understanding
³ SHRDLU：積み木世界で自然言語文を理解して計算機の中の
のロボットハンドが積み木を移動
19
積み木の世界(Blocks World)
² SHRDLU(Winograd, 1972) 
² 積み木を自然言語の命令で動かす
² 決められた問題でのプランニング
20
フレーム問題
² ロボットに「時限爆弾を机の上から取り除き、
部屋の外に持ち出せ」という指令が与えられた。
21
フレーム問題とロボットの思考
1.
ロボット一号は命令通り愚直に机の上から爆弾を持ち上げ
たところ爆発してしまった。机の上から離れると爆発すると
いう発火条件が爆発には仕込まれていたのだ。
2.
そこで、ロボット二号はあらゆる条件を事前に考えるように
作られた。その結果、ロボット二号は停止してしまった。なぜ
なら，壁との距離，温度，机との関係，椅子との関係，光の
当たり方などなど，考える対象は現実世界では無限にあっ
たからである。ロボットがあらゆる可能性を考えている内に，
時間が経ってしまい時限爆弾は爆発してしまった。
3.
そこで，ロボット二号での問題点を解決するべく，ロボット三
号は考える必要のないことは考えないように改良された。部
屋に入ったロボット三号は，この課題において「何が関係な
いか」を一つ一つ考えていった。壁との距離は関係ない，温
度は関係ない，椅子との関係は関係ないなどなど，ロボット
があらゆる関係ないものの可能性を考えている内に，時間
が経ってしまい時限爆弾は爆発した。
壱
弐
参
22
フレーム問題
² 一般化フレーム問題
³ 限られた処理能力しかない人工知能は、現実に起こりうる
問題すべてに対処することができない
³ 自然に発生した知能（人間の知能）についても言われる
23
1980年代から
² 1980年代
³ 行動主義ロボティクス（ロドニー・ブルックス）
® サブサンプションアーキテクチャ
³ 第五世代コンピュータプロジェクト （日本の国家プロジェクト）
² 1990年代
³ ソフトコンピューティング
® ニューラルネットワーク，ファジィ理論，遺伝的アルゴリズム
³ オントロジー
® エキスパートシステムの発展
³ WWWの普及と計算の高速化、データマイニング
³ 複雑系（人工生命，カオス，フラクタル，ネットワーク科学）
24
1990年後半以降
25
² エキスパートシステムの失敗から新しいアプローチへ
³ ブール論理→確率論理
³ ハンドコーディング→機械学習
³ 哲学主義→実験主義
² 共有されたベンチマークの普及
³ UC Irvine repository（機械学習）
³ LibriSpeech, MNIST, ImageNet, COCO（パターン認識）
³ SQUAD, WMT competition（自然言語処理）
² 良い人工知能研究の評価基準の変化
³ 直感やヒューリスティック→厳密な証明や確実な実験
³ トイプロブレム→現実的なアプリケーション
Deep Blue (IBM)
² 1997年: チェス世界チャンピオン
（Kasparov)に勝利
² 1秒間に2億手の先読み
² 対戦相手となる人間の思考を予測
² 対戦相手の過去の棋譜をもとに
評価関数を設計
26
ビッグデータの誕生
27
² 様々な形をした、様々な性格を持った、様々な種類のデータ
² World Wide Webの発展により膨大な量のデータ創出が促進
³ テキスト, 画像, 音声, 動画など
² ビッグデータの3つのV
³ データの量（Volume）
³ データの種類（Variety）
³ データの発生頻度・更新頻度（Velocity）
² ビッグデータにより急激に機械学習の性能が向上
³ センサーネットワーク
³ ソーシャルネットワーク、ビッグソーシャルデータ分析
³ インターネット文書、インターネット検索
³ 天文学、大気科学、ゲノミクス、生物地球化学、生物学など科学研究
³ 軍事偵察、医療記録、メディアアーカイブ
³ 大規模なeコマースなどのビジネス
Watson (IBM)
² IBMが開発した質問応答システム
² 2009年4月:クイズ番組「ジョパディ！」にチャレンジし
総合優勝
² 自然言語理解、検索、分散データベース等を駆使
² 今後、医療診断、ゲノム解析、ヘルプデスクでの顧客
サービスなどに活用
28
ディープラーニング
² 多層ニューラルネットワーク
³ 特徴の自動抽出ができる！
³ 物体認識の精度を競う国際コンテスト(ILSVRC)で、トロント大学の
チームがディープラーニングによってダントツ優勝
³ 米GoogleがYouTubeの画像を見せ続けディープラーニングによって
学習させた結果、猫の画像を猫と認識できるようになった
http://business.nikkeibp.co.jp/article/bigdata/20150419/280107/
29
第3次AIブーム
1.
Webが発展して、ビッグデータが誕生
³
膨大な学習データは必須
2.
ディープラーニングにより特徴を自動抽出できる
3.
計算機パワーの上昇
³
ディープラーニングは無尽蔵な計算機パワーが重要
30
第3次AIブーム
•
AlphaGoが人間のプロ囲碁棋士に勝利
•
人工知能研究に研究資金が投じられる
AIの発展と脅威
31
² AI分野は脅威的なスピードで発展
³ 2010~2019年に年間2万本の論文が発表
® 1. 機械学習, 2. コンピュータビジョン，3. 自然言語処理
® 国別出版数は1.中国, 2.US（ただし，USの方が引用指数は50%高い)
³ AIを専攻する学生数は2010年よりUSで5倍，世界で16倍
³ 人間よりも高性能もしくは同等のタスク
® Chess, Go, Poker, Jeopardy!(クイズ)
® Pac-Man,Quake III, Dota 2, StarCraft II, Atari games(ビデオゲーム)
® 画像認識, 音声認識, 自動翻訳
® 医療診断（がん診断など）
² AIの広い範囲でのリスクと倫理的影響についても認識する必要性
³ Super intelligent AIを制御する
® シンギュラリティ：AIが十分に賢くなり自身より賢いAIを作れるようになった瞬間
³ 人工知能のガイドラインや法整備を進める
³ 人工知能が発展した時に消える仕事など→雇用への影響
まとめ
² 人工知能の導入
³ 人工知能とは何か？= 人によりさまざま
² 人工知能の歴史
³ 歴史的によき時代と冬の時代が繰り返されている
（今は再び活性化の時代）
32
人工知能
基本的な探索
（幅優先、深さ優先）
東京農工大学工学部知能情報システム工学科
藤田桂英
(katfuji@cc.tuat.ac.jp)
1
内容
² 探索（Search）
³ 問題の定式化
³ 探索木と探索アルゴリズム
² 知識を用いない探索アルゴリズム
³ 幅優先探索
³ 深さ優先探索
³ 深さ制限探索
³ 反復深化探索
³ 双方向探索
2
探索（Search）
•
問題の定式化とその解決
– 状態空間
– 状態遷移（次の状態の定義）
– 始状態
– ゴール状態（その判定）
•
解から得られるものについて
– 解の有無
– 解そのもの
– 解への経路
– 最短経路
– 最小コストの経路
3
○
○
○
○
○
○○
○
○
○
○◎
○
探索による解決例
•
迷路抜け問題
•
宣教師と土人問題
•
８人の女王
•
スライドパズル
•
図形詰込問題
•
ナップサック問題
4
探索アルゴリズムの種類
5
• 幅優先探索
• 深さ優先探索
• 深さ制限探索
• 反復深化探索
• 双方向探索
• 最小コスト優先探索
• 最良優先探索
• A(A*)アルゴリズム
• メモリを制限した探索
• IDA*
• SMA*
• 局所探索
• 山登り法(HC)
• 焼きなまし法(SA)
• 遺伝的アルゴリズム
(GA)
知識を用いない探索
（ゴールor 非ゴールの知識のみ）
知識を用いた探索
(コスト等の情報あり)
² 条件
³ 迷路の中でエージェントがどこにいるか認識できる
³ 問題は連続的な迷路の空間から適切な離散状態空間を構成
= マス目に簡単に分割できる問題を仮定
³ 物理的につながっている場所・状態には、確定的に移動できる
= 突然道がふさがる、エージェントが故障することは考えない
迷路抜け問題
あるロボットがスタート地点にいます。
ロボットの手元には完全な地図があり、ゴール地点も示され
ています。
このとき、スタート地点からゴール地点に行くためには、どの
よう経路でいけば良いのかをエージェントは考えます。
6
² 1 マス1 マスを一つの状態として捉える
² 各状態をノード、状態間の遷移をリンクとする
→グラフ構造or 木構造
状態空間の表現
7
² 状態：地図上の１マス
² 初期状態：スタート地点
² 目的状態：ゴール地点
² 行為：エージェントが１マス移動すること
² 経路コスト：地図の1マスを通過したら１増える
迷路抜け問題の定式化
8
問題定式化の例（8クイーン）
² 状態空間
³ クイーンを上の段から何段か(0から8)配置した盤すべて
² 状態遷移（次の状態の定義）
³ 現在位置は、N段目まで配置してあるとする
³ それに加えて、N+1段目、左から右まで８マスそれぞれにクイーンを
一つ置いた盤８通り
³ ただしN段目までのクイーンと縦横斜めに重なる場合を除く
² 初期状態
³ まだクイーンを配置していない盤
² 目標状態
³ 8段目まで全部クイーンがおかれた盤
チェス盤（8×8)にクイーン８個を互いに取れない
（縦横斜めに重ならない)位置に置く
9
演習1: 迷路からの状態空間構成
² 下記の迷路において「分岐」と「行き止まり」について
のみ状態をおいて状態空間を構成し，グラフ表現せよ
10
探索木
² 根(root): 初期状態
² 枝（エッジ）:状態遷移
² ノード：状態
² 葉：目標状態or 非目標状態
12
根
枝
ノード
葉
目標状態
² 探索= 初期状態から目標状態への経路を探す
² 解=目標状態へ至る行動
² 知識を用いない探索アルゴリズム
³ 「どの状態はすでに調べたか」「どの状態はまだ探して
いない」というような情報を管理
³ 効率的にしらみつぶしに探索
探索アルゴリズム
13
² オープンリストとクローズドリストという二つのリスト(CL,OL)
³ オープンリスト: 発見済でこれから探査するノードを管理するリスト
³ クローズドリスト: すでに探査が終了したノードを管理するリスト
基本となる探索アルゴリズム
OL:オープンリスト, CL:クローズドリスト, x:現在のノード
next(x,L): Lに含まれないxの子ノードリストを返す関数
Step 1: OL:={a}, CL={ }
Step 2: OL={ } ならばfalseを返して終了
Step 3: xをOLから取り出す
Step 4: xがゴール状態ならばTrueを返して終了
Step 5: xをCLを追加
Step 6: OLにnext(x,CL)の返却値を追加
Step 7: goto Step 2
14
² オープンリストには発見済かつこれから探査する状態が格納
² クローズドリストには探査済の状態が格納
² 現在の状態は、オープンリストからクローズリストに移動される
オープンリスト(OL)とクローズドリスト(CL)
15
入力値=[x:現状態, CL:クローズドリスト] 
返却値={次に進める状態の集合}
1. 現状態から次に進める状態を調べる
³
現状態から上下左右の状態が壁か道か判定
2. 次に進める座標がCLに入っている場合は、
返却値から除外する
3. 次に進める状態のリスト（集合）を返す
next(x,CL)について
16
² 同じ深さのノードを調べ終わってから、次の深さに進む
² オープンリストの構造= キュー
幅優先探索
17
²
進めるかぎり掘り進めて行き詰まったら次の枝を調べる
²
オープンリストの構造がスタック
深さ優先探索
18
探索の評価基準
19
² 完全性
³ 正しい解が見つかることを保証するか
² 時間計算量
³ 解を見つけるのにどのぐらい時間がかかるか
² 空間計算量
³ 探索に必要なメモリの量
² 最適性
³ 異なる解が複数あるときに最もよい解を選ぶか
幅優先探索
20
² 完全性と最適性を保証
³ 深さが浅いものから順番に展開
² ノードの最大探索数（時間・空間計算量）
³ 1+b+b2+b3+・・・+bd = O(bd)
³ b:ノードからの経路の数，d:解の存在する深さ
メモリを大量に使う→他の探索方法で解決
時間がかかる→他の探索方法で解決できない
・・・
︓展開済み
︓未展開
︓解(未展開)
深さ優先探索
21
︓展開済み
︓未展開
︓解(未展開)
ta
行き止まり
︓リストから呼び出し
深さ優先探索
22
² 空間計算量: O(bm)
³ b:ノードからの経路の数，m: 木の最大の深さ
³ 根からから葉までの経路を保存
² 時間計算量: O(bm)
³ 全てのノードを探索した場合
² 完全性と最適性は保証されない
³ 探索木の深さが無限（非常に深い）時に解が
見つからないことがある
演習2 幅優先探索
下図のグラフに関して，S を初期状態として幅優先探索を行え．
ただしそれぞれについて，オープンリストとクローズドリストの変化も
示すこと．
23
演習3 深さ優先探索
下図のグラフに関して，S を初期状態として深さ優先探索を行え．
ただしそれぞれについて，オープンリストとクローズドリストの変化も
示すこと．
25
深さ制限探索
27
² 基本は深さ優先探索
² 深さをl に制限する
³ 深さが膨大な場合でも探索可
³ 深さの制限が小さくしすぎる→解が見つからない
︓展開済み
︓未展開
︓解(未展開)
︓リストから呼び出し
ta
深さの限界l = 1の場合
Depth=1
深さ制限探索
28
² 基本は深さ優先探索
² 深さをl に制限する
³ 深さが膨大な場合でも探索可
³ 深さの制限が小さくしすぎる→解が見つからない
² 時間計算量: O(bl)
² 空間計算量: O(bl)
² 完全性と最適性は保証されない
反復深化深さ優先探索
29
² 深さ(Limit)を変更しながら深さ制限探索
→幅優先探索+深さ優先探索
・l=0
・l=1
・l=2
・l=1
・l=1
・・・
・l=2
反復深化深さ優先探索
30
² 問題点: 同じ上位ノードが複数回展開される
³ b=10，d=5の時
³ 深さ制限探索での展開数は111,111
® 1+10+100+1,000+10,000+100,000=111,111
³ 反復深化深さ優先探索では123,456
® 6+50+400+3,000+20,000+100,000=123,456
³ 深さ制限探索よりもたった11%だけ展開数が増加
² 時間計算量O(bd)，空間計算量O(bd)
解の深さが分からない時に望ましい
双方向探索
31
² スタートとゴールの両方から探索を始める
双方向探索
32
² 深さが1/2になる→計算量の削減
² b=10，d=6の時の展開数
³ 幅優先探索: 1,111,111ノード
³ 双方向探索: 2,222ノード
² 問題点
³ ゴールからどのように展開するか
³ 前ノードを定義できるか？
³ ゴール状態が複数あるときの対応
² 双方向とも幅優先探索→完全性、最適性を保証
² 時間的・空間的複雑性: O(bd/2)
知識なし探索手法のまとめ
33
幅優先
深さ優先
深さ制限
反復深化
双方向
完全性
Yes *a
No
No
Yes *a
Yes *a,c
時間
O(bd)
O(bm)
O(bl)
O(bd)
O(bd/2)
空間
O(bd)
O(bm)
O(bl)
O(bd)
O(bd/2)
最適性
Yes *b
No
No
Yes *b
Yes *b,c
*a: bが有限の場合に完全性あり
*b: ステップコストが全て同一の場合最適性あり
*c: 双方向からの探索が幅優先探索の場合
b:ノードからの経路の数, d:解の存在する深さ
m:木の最大の深さ, l:深さの制限値
人工知能
最適経路探索
（A*アルゴリズム, 最良優先探索）
東京農工大学工学部知能情報システム工学科
藤田桂英
(katfuji@cc.tuat.ac.jp)
1
探索（Search）
•
問題の定式化とその解決
– 状態空間
– 状態遷移（次の状態の定義）
– 始状態
– ゴール状態（その判定）
•
解から得られるものについて
– 解の有無
– 解そのもの
– 解への経路
– 最短経路
– 最小コストの経路
2
○
○
○
○
○
○○
○
○
○
○◎
○
探索による解決例
•
迷路抜け問題
•
宣教師と土人問題
•
８人の女王
•
スライドパズル
•
図形詰込問題
•
ナップサック問題
3
探索アルゴリズムの種類
4
• 幅優先探索
• 深さ優先探索
• 深さ制限探索
• 反復深化探索
• 双方向探索
• 最小コスト優先探索
• 最良優先探索
• A(A*)アルゴリズム
• メモリを制限した探索
• IDA*
• SMA*
• 局所探索
• 山登り法(HC)
• 焼きなまし法(SA)
• 遺伝的アルゴリズム
(GA)
知識を用いない探索
知識を用いた探索
最短パス探索問題
コストの和を最小化するA→F or Gの経路を求める
A
3
B
2
C
F
E
1
3
3
D
2
H
G
I
J
2
3
1
5
コスト付き探索木
² 探索木の枝にコストを追加
³ コスト: 状態を遷移する際に必要な値
³ コストは正の値
² 最適解=最小のコストを持つゴール
6
A
B
1
D
2
F
2
E
3
C
H
G
J
I
2
1
3
3
3
ヒューリスティック関数・値の導入
c
c
g(n)
h’(n)
(観測できないので、推定する)
f’(n)
g(n)
初期状態から状態nまでの最適経路上のコストの総和
h(n)
状態nからGoalまでの最適経路上のコストの総和
f(n)
状態nを経由した場合の最適経路のコスト(f(n)=h(n)+g(n))
h’(n)
h(n)の推定値。状態nの予測評価値（ヒューリスティック関数）
f’(n)
f(n)の推定値（f’(n)=h’(n)+g(n))
状態n
（観測可能）
Goal
7
探索木と評価関数
² 理想的な評価関数の場合
² h*(n): ノード付近の括弧の数字
³ h*(n)=0: ゴール, h*(n)=∞: 葉ノード
8
A
B
1
D
2
F
2
E
3
C
H
G
J
I
2
1
3
3
3
(4)
(3)
(∞)
(0)
(0)
(∞)
(∞)
(∞)
(3)
(10)
評価関数と探索アルゴリズム
² 理想的な評価関数が利用可能
→無駄のない探索が可能
² ほとんどの問題で理想的な評価関数は利用不可能
³ 理想的な評価関数がわかれば探索の必要がない
² 理想的な評価関数の近似を利用
9
近似評価関数
探索アルゴリズム
f(n)=1
幅優先探索
f(n)=g(n)
最小コスト優先探索
f(n)=h’(n)
最良優先探索
f(n)=g(n)+h’(n)
A*(A)アルゴリズム
h’(n)はh(n)を近似する関数
最小コスト優先探索(Uniform-Cost Search)
² 評価関数としてノードのコストg(n)だけ利用
³ ヒューリスティック関数を利用しない
² コストが小さいノードの探索を優先する
c
c
g(n)
この部分に着目
状態n
10
最小コスト優先探索アルゴリズム
1.
初期状態をOLに追加．CLを空に初期化．
2.
while OLが空でないdo
1.
OLから先頭要素nを取り出す．CLにnを追加．
（この部分が探索に相当する）
2.
if (n==[目標状態]) then 解が発見されたとして終了．
3.
nから接続かつまだ未探索の全状態をOLに追加．
4.
if (OLのg(n') > 現在のg(n')) then OLのg(n')を更新．
（小さい累積コストであることが判明した場合は更新）
5.
OL内の全状態を累積コストg(n)の小さい順にソート．
3.
end while
11
*OL: オープンリスト、CL: クローズドリスト
最小コスト優先探索の利点と問題点
² 最適性あり
³ コスト最小のノードから訪問→最初に見つけた解=最適解
³ 無限に続く経路→コストが高くなるので抜け出せる
² コストが均一に近い=幅優先探索に近くなる
³ 時間計算量が指数関数的
² 状態nからゴールへのコストが考慮されていない
³ ヒューリスティック情報が活用されていない
12
50
100
1000
200
先に展開される
演習1 最小コスト優先探索
² 下のグラフにおいてSからスタートして最小コスト
優先探索でGを探索せよ。探索中の様子をオー
プンリストで示し、最終的に得られる経路を示せ。
S
A
B
G
C
1
D
3
5
5
1
2
1
5
(4)
(1)
(1)
(3)
(3)
(0)
13
最良優先探索(Best-first search)
² 評価関数としてヒューリスティック関数h’(n)だけ利用
³ h’(n)はh(n)の見込みを表す
® h’(n)の計算はh(n)より計算が容易である必要がある
® h’(n)>0
² 見込みが高いノードから展開
→幅優先・深さ優先より早く解にたどり着ける
h’(n)
この部分に着目
状態n
15
最良優先探索アルゴリズム
1.
初期状態をOLに追加．CLを空に初期化．
2.
while OLが空でないdo
1.
OLから先頭要素nを取り出す．CLにnを追加．
（この部分が探索に相当する）
2.
if (n==[目標状態]) then 解が発見され終了．
3.
nから接続かつまだ未探索の全状態をOLに追加．
4.
OL内の全状態をh’(n)の小さい順にソート．
3.
end while
16
※OLはオープンリスト，CLはクローズドリストとする．
※h’(n): nの推定値
最良優先探索の利点と問題点
² よい評価関数が利用できれば効率がよい
² 最適性がない
² 完全性がない
17
1
1
1
1
1
(1)
(1)
(2)
コスト=3
コスト=2
先に見つかる
1
1
1
1
1
(1)
(1)
無限に続く
(1)
(2)
演習2 最良優先探索
² 下のグラフにおいてSからスタートして最良優
先探索で探索せよ。探索中の様子をオープン
リストで示し、最終的に得られる経路を示せ。
S
A
B
G
C
1
D
3
5
5
1
2
1
5
(4)
(1)
(1)
(3)
(3)
(0)
18
A(A*)アルゴリズム
² g(n)とh’(n)を両方用いたアルゴリズム
³ 評価関数: f’(n)=g(n)+h’(n)
³ オープンリストからf’(n)が最小のノードを展開
c
c
g(n)
h’(n)
f’(n)
ここに着目
状態n
20
A(A*)アルゴリズム
1.
初期状態をOLに追加．CLを空に初期化．
2.
while OLが空でないdo
1.
OL から先頭要素nを取り出す. CLにnを追加．（探索に相当）
2.
if(n==[目標状態]) then 解が発見されたとして終了.
3.
nから接続されている全状態n’に対してf’(n’)=g(n’)+h’(n’)を計
算．
4.
if(nに接続する全状態n’のうちOLにもCLにも含まれてい
ない) then OLに追加．
5.
if([nに接続する全状態n’のうちOLかCLに含まれている] and
[すでに入っているf’(n’)>現在のf’(n’)]) then 新しいf’(n)に更新．
更新したものをOLに追加．
6.
OL内の全状態をf’(n)が小さい順にソート．
3.
end while
21
※OLはオープンリスト，CLはクローズドリストとする．
※g(n’): Sからn’に到達するまでのコストの総和，h’(n’): n’の推定値．
A*アルゴリズム
² すべてのノードnについてh’(n)≦h(n)が成立する
時、Aアルゴリズムを特にA*アルゴリズムと呼ぶ
³ 適切な予測評価値がわからない場合については、
推定値は小さめに設定する方がよい
³ h’(n)=0とすると最小コスト優先探索と一致
22
A*アルゴリズムの特徴
² 最適性あり（必ず最適解を発見する）
² 完全性あり（必ずゴールに到達する）
² 時間計算量：𝑂(𝑏!)
³ 幅優先探索と同様
³ ヒューリスティック関数の誤差が実際の経路コス
トの対数より早く増加する→指数関数的に増加
² 空間計算量：𝑂(𝑏!)
³ すべてのノードを記憶するため
※ b:ノードからの経路の数, m:木の最大の深さ
23
A*アルゴリズムの
完全性と最適性の証明
² 完全性を証明
³ g(n)>0を利用
³ g(n)は深いノードほど単調に増加する
² 最適性を証明
³ h’(n)≦h(n)を利用
³ 最小コストではないゴールが見つかると仮定
24
証明のための仮定
1. 枝コストは正値をとる
2. h’(n), h(n)は非負
3. h’(n), h(n)は葉ノード以外は有限値
完全性の証明
² 有限の探索木
³ 最悪、全ノード探索後にA*は停止し、
解を発見
² 無限の探索木
³ 任意の経路(a1,a2,a3…)について
(枝コスト)>0 →g(a1)<g(a2)<…
³ 経路A(a1,a2,a3…)が無限経路系列
³ 経路B(b1,b2,b3…)が解経路系列
³ f(bj)が有限かつg(ai)が単調増加
→f(bj)<g(ai)(j=1,2,..,n) を満たす
最小のiが存在
³ h(n)≧0よりg(ai)≦g(ai)+h(ai)≦f(ai)
³ 以上から、f(bj)<f(ai) (j=1,2,..,n)なの
でbjはaiより先に展開される
→必ず解を発見できる
25
b1
b2
a1
bn
1
b3
無限に続く
ゴール
a2
a3
a4
f(bj)<f(ai)
最適性の証明
26
S0
a
s
² 最適解ではないtが最適解sより先に見つかると仮定
= s0からsの経路上でf’(a)>f(t)となるaが存在すると仮定
aの理想評価関数: f*(a)=g(a)+h(a)=g(s)--①
不等式h’(a)≦h(a)を①に適用g(a)+h’(a)≦g(s)
一方、sは最小コストの解であるからg(s)<g(t)
g(a)+h’(a) ≦g(s) < g(t)
f’(a)=g(a)+h’(a)<g(t)+h(t)=f(t) (h’(t)≧0より)--②
②はオープンリストでは任意のaがtより先に展開されるに矛盾
→仮定: 最適解ではないtが最適解sより先に見つかるがおかしい
t
最小コストのゴール
g(s) < g(t)
最小コストではないゴール
演習3 A*アルゴリズム
² 下のグラフにおいてSからスタートしてA*アルゴ
リズムで探索せよ。探索中の様子をオープオン
リストで示し、最終的に得られる経路を示せ。
S
A
B
G
C
1
D
3
5
5
1
2
1
5
(4)
(1)
(1)
(3)
(3)
(0)
27
コスト優先vs 最良優先vs A*
² コスト優先探索
³ 経路のコストは明確にわかっている
³ ノードの推定コストはわからない
³ 最適性、完全性あり
² 最良優先探索
³ これまでの経路のコストを考慮してしない
³ ノードの推定コストを考慮
³ 最適性、完全性なし
² A(A*)アルゴリズム
³ 経路のコストを考慮している
³ ノードの推定コストを考慮している
³ 最適性、完全性は一定の条件の下で保証
® A*アルゴリズムの時
完全性
最適性
コスト
優先
○
○
最良
優先
×
×
A*
○
○
29
ヒューリスティック関数の決定
² 8パズル
³ 配置: 9!通り、探索空間: 320=3.5×109
³ ヒューリスティック関数: h(n)の設計
® h1(n): 間違った場所にあるタイル数
® h2(n): ゴールとのマンハッタン距離の合計
30
h(n)の精度と探索性能
² 有効分岐数: b*
³ 展開されたノードの総数:N, 解の深さ：d
³ どれだけ展開したか/しなければいけないかを
² 深さdの均一の木がN+1個もつための分岐数がb*
N+1=1+b*+(b*)2+…+(b*)d
（例) 52個のノードを用いて深さ5の解を見つけた
52+1=1+b*+(b*)2+…+(b*)d ⇔b*=1.92
³
b*が1に近づくほど優れている
®
分岐の必要がないため
31
² A*アルゴリズムの方が優れている
² h2(n) > h1(n) （h2(n)の方がノードの展開数が少ない)
32
ヒューリスティック関数の決定
² 弱条件問題（Relaxed Problem)
³ 元の問題より良い性能を発揮する場合が多い
² 例
³ 8パズルのルール
® AがBの隣でBが空いていれば、AからBへタイルを動かすことが
できる
³ 弱条件問題
® AがBの隣であれば、AからBへタイルを動かすことができる
® Bが空いていれば、AからBへタイルを動かすことができる
³ ABSOLVER(1993)
® ルービックキューブに有効なヒューリスティックを発見
² 統計情報を用いる
² 状態の特徴を用いる
³ 将棋の盤面の特徴（持ち駒数、攻撃されている駒数など）
33
メモリを制限したA*アルゴリズム
² IDA* (Iterative Deepened A*)
³ 反復深化探索+A*アルゴリズム
³ fの制限値foutに基づいて、反復する
³ 制限値を超えた評価値の最小値を次回の制限値とする
² SMA*(Simplified Memory-bounded A*)
³ メモリが一杯になるまで最適な葉ノードを展開しながら、A*
探索と同様に探索
³ メモリが一杯になった時点で、fの値が一番高い葉ノードを
捨てる
³ 最適解の可能性の低いノードを忘れることによってメモリを
節約
34
まとめ
² 知識を用いた探索
³ 最小コスト優先探索: f(n)=g(n)
® 完全性、最適性あり
³ 最良優先探索: f(n)=h’(n)
® 完全性、最適性なし
³ A(A*)アルゴリズム: f(n)=g(n)+h’(n)
® h’(n)≦h(n)ならばA*アルゴリズム
® A*アルゴリズムは完全性、最適性あり
² ヒューリスティック関数の決定
35
人工知能
メタヒューリスティック探索
(HC, SA, GA)
東京農工大学工学部知能情報システム工学科
藤田桂英
(katfuji@cc.tuat.ac.jp)
探索（Search）
•
問題の定式化とその解決
– 状態空間
– 状態遷移（次の状態の定義）
– 始状態
– ゴール状態（その判定）
•
解から得られるものについて
– 解の有無
– 解そのもの
– 解への経路
– 最短経路
– 最小コストの経路
○
○
○
○
○
○○
○
○
○
○◎
○
探索による解決例
•
迷路抜け問題
•
宣教師と土人問題
•
８人の女王
•
スライドパズル
•
図形詰込問題
•
ナップサック問題
探索アルゴリズムの種類
• 幅優先探索
• 深さ優先探索
• 深さ制限探索
• 反復深化探索
• 双方向探索
• 最小コスト優先探索
• 最良優先探索
• A(A*)アルゴリズム
• メモリを制限した探索
• IDA*
• SMA*
• 局所探索
• 山登り法(HC)
• 焼きなまし法(SA)
• 遺伝的アルゴリズム
(GA)
知識を用いない探索
（ゴールor 非ゴールの知識のみ）
知識を用いた探索
(コスト等の情報あり)
Local Search（局所探索）
² 厳密性を保証しない方法
² [現状態] と[すぐ次の状態] のみを評価し，
状態を変化させながら探索を進めていく
³ 解を出すまでの過程は保持しない→ 使用メモリ小
³ 莫大な数の状態が存在しても適当な解を求めやすい
³ 最適化問題を解くのに適している
² 有名な手法
³ 山登り法（Hill-climbing search）
³ 焼きなまし法（Simulated annealing）
³ 遺伝的アルゴリズム（Genetic algorithm）
8-Queens Problem
² 「条件:クイーン同士が攻撃不可」を満たすように，
チェスボードに8つのクイーンを置く（各列に1つ）
³ クイーンは縦・横・斜めに何マスでも移動できる
（将棋の飛車と角の動きを足したようなもの）
³ 条件を満たすクイーンの配置が解となる
² Local search で
解くことができる問題の一つ
正解
（ゴール状態）
山登り法
(Hill-Climbing Search(HC))
² 候補となる次の状態の中から現状態より良くなる
ものを選び，その状態に変更
² 状態を改善することができなくなった時点で終了
² 適当な解を
高速に導ける
↓
最適解と限らない
状態
目的関数
(objective function)
状態空間
(state space)
山登り法のアルゴリズム
Input: problem, a problem
Output: a solution node
function HILL_CLIMBING(problem)
Node current
Node next
current ← MAKE_NODE(INITIAL_STATE[problem])
loop do
next ← a highest valued neighborhood of current
if VALUE[next]≦VALUE[current] then return current
else current ← next
end loop
山登り法の問題点
² Local Optimal（局所最適解）
³ これ以上の状態改善は行えないが，最適状態ではない
² Plateau（高原）
³ 移動しても状態の良し悪しが変化しない状況
Global Optimal
Local Optimal
flat local optimal
状態
Shoulder
目的関数
(objective function)
状態空間
(state space)
山登り法の改良
² Stochastic Hill Climbing （確率的山登り）
³ 改善度に関係なく、複数の改善する選択肢から
次状態をランダムに選択
³ 収束は遅くなるが、局所最適解に陥りにくくなる
² Random-restart hill climbing
³ 得られた解が最適でない場合、
初期状態をランダムに
設定して探索を繰り返す
³ 局所最適解に陥りにくくなる
state space
object
function
current state
①
②
③
通常の山登り法→①
確率的山登り法→①~③
からランダムに選ぶ
焼きなまし法
(Simulated Annealing(SA))
² 現状態から悪くなる方向への変化も許す
⇔Hill climbing は今より良い状態のみを次の候補にした
² 次になりうる状態の中からランダムにnext を選ぶ
³ 1. 現状態より良いならばnext に変更
³ 2. 悪くなる場合は，一定の確率Pでnext に変更
® Pは，時間の経過と悪くなる度合いに応じて減少していく
² SAのイメージ
³ でこぼこの地面を揺らして
一番深い溝にボールを落とす
³ 揺らす強さを徐々に
小さくしていく
state space
cost
lower
is
better
焼きなまし法のアルゴリズム
Input: problem, a problem
schedule, a mapping from time to temperature
Output: a solution node
function SIMULATED_ANNEALING(problem, schedule)
Node current
Node next
Value T
current ← MAKE_NODE(INITIAL_STATE[problem])
for t←1 to ∞do
T ← schedule[t]
if T=0 then return current
next ← a randomly selected neighborhood of current
ΔE ← VALUE[next] – VALUE[current]
if ΔE > 0 then current ← next
else current ← next with probability expΔE/T
焼きなまし法の利点
² ランダム性を有している→局所的最適解に
陥ることを回避し、大域的最適解に到達可能
² 温度(T)の設定
³ 初期温度をできるだけ高い値にする
³ 時間が経過するにしたがって、徐々に温度を
低下させる
³ 実際は適切な温度関数を設定するのは大変
Local Beam Search
² 複数個の現状態を保持し，それぞれにおける探索を
並列に行う
³ 並列に動いているスレッド同士で情報交換を行い、
それぞれにおける最善を保持する
³ いずれかが解に辿り着いた時点で終了
² Stochastic local beam search
³ 複数の現状態とそれぞれの次の状態をランダムに決める
³ Genetic algorithm（遺伝的アルゴリスム）はこの一種
Tabu Search
² 過去の状態遷移に関する記録を利用して
無駄なループを避ける
² タブーリスト: 過去の状態遷移の記録
³ 記録する情報の種類、リストの長さによって探索
の挙動を制御
³ タブーリストのリセットによりどこにも遷移できない
状態を防ぐ
タブーサーチのアルゴリズム
1.
初期状態S0 を決定する
2.
最良状態Sb と現在状態S を作成、S0 を両方に記録
3.
S の近傍を複数（M 個）選び、その中で最良の近傍を
S' とおく
4.
状態遷移を判定
1.
if eval(S’)>eval(Sb): Sb =S =S' このときタブーリストに
S →S' になる操作が記載されている場合、その部分をタ
ブーリストの一番新しい記載に移動
2.
if eval(S’)<eval(Sb): S →S’ になる操作がタブーリストに
記載されているかどうかを確認。記載されていないならタ
ブーリストにS →S' となる操作を記載してS =S' とする。
® タブーリストのサイズが上限を越えている→一番古い記載を削除
5.
終了条件が満たされるまで3と4の操作を繰り返し、
Sb を解として出力
遺伝的アルゴリズム
(Genetic Algorithm (GA))
² 二つの現状態（親）から次の状態（子）を決定する
1.
複数の現状態が存在
2.
各状態に評価値を決定し、それに応じた割合で親を選ぶ
（増殖・淘汰)
3.
情報を交叉するポイントの決定
4.
交叉ポイントを境に親同士の情報を入れ替える（交叉）
5.
偶発的に情報を変化させる（突然変異）
²
8-queen problem にGA を適用させた例
交叉
² 遺伝子の交差（交叉）つまり交換する
² よい遺伝子同士が出会う機会を飛躍的に高める
ことが重要
² 交叉の種類
³ 一点交叉法
³ 二点交叉法
³ 多点交法
³ 一様交叉法
® 各要素ごと独立に1/2の確率で入れ換える
多点交叉法の例
増殖・淘汰
² 遺伝的アルゴリズムでの増殖・淘汰
³ 適応度関数による評価値で選択
³ 勝敗によることもある
³ データのコピーおよび削除
² 選択方法
³ ルーレット選択、ランキング選択、トーナメント選択
期待値による選択の例
突然変異
² データのランダムな変更
² 局所最適解に陥るのを防ぐ
² あまり確率が大きいとランダムサーチになる
連続空間におけるLocal Search
² 状態の変化が連続的である場合，
次の瞬間に生じうる状態が多すぎる
³ 連続的⇔離散的=想定される状態が有限個
³ 連続な値の例）時間，目盛りがない空間における位置
→連続的な問題をlocal search で扱うのは困難
² 連続的な値を離散化することで対応可能
³ 例1) 時間の変化の最小単位をn秒とする
³ 例2) 一回の移動量をx で固定する
連続的
離散的
非決定的な環境における探索
² 次状態を一意に定められない
³ ある操作による結果にランダム性が伴う
³ 現実世界ではこのような問題が多い
³ 例）8-queen problem において，手が滑ってしまい予期
せぬマスにクイーンを配置
² 起こりうる現象を全て想定した上での探索が
必要になる
Erratic Vacuum World
² Goal：全てのマスを綺麗にする
³ 可能な操作：Left(左移動)，Right(右移動)，Suck(ゴミの吸引)
² Suck を非決定的な操作として扱う
³ ゴミがあるマスでSuckを行うと，
横のマスのゴミも吸うことがある
³ ゴミがないマスでSuckを行うと，
逆にゴミを排出することがある
² 生じうる結果を全て想定し，
if文やcase文を用いて解を表す
³ 例）状態1からの解↓
[Suck, if State=5 then [Right, Suck] else []]
Goal
AND-OR Search Trees
² 非決定的な環境で利用される探索木
³ OR node とAND node で構成
® OR node：
操作の違いによる分岐
® And node：
偶発的な分岐
³ 全ての葉がGOAL
® 葉への最短経路を求める
® 太い矢印: 状態1からの解
OR node
AND node
オンライン探索
² 探索と行動を交互に行う
³ 現時点の完全な解を計算した後，
解を実行
² オフライン探索
³ 行動する前にすべての解を計算
³ 起こりうることすべて考慮
² 様々な分野で活用できる
³ 動的な問題設定
³ 非決定的分野
² HC, SA, GAはオンライン探索
³ 現状態と次状態のみ考慮
どちらか分からない
RTA*
² すべての状態に推定コストを付与する
² ゴールに到達するまで以下のステップを繰り返す
² 先読み(look ahead): 
³ f(x’) = k(x,x’)+h(x’)をxに隣接するすべての状態x’に対して計算
³ h(x’)はx’からゴールにいたる推定コスト
³ k(x,x’)はxからx’にいたる実際のコスト
² 更新:
³ 状態xの推定コストh(x)をf(x’)のうち2番目に小さい値に更新
³ 移動:f(x’)の最小のノードx’に移動
² 必ずゴールを発見できる(完全性を保証) 
LRTA*
² RTA*を繰り返し実行することによって、評価値を更新し、
最適解に収束する
² 問題点
³ すべての最適値を求め続けてしまう
® 実時間処理では、最適解が必ずしも必要ではない
³ 最適解が漸次的に求められるわけではない
® 段階的に収束していくわけではない
³ 今まで得られた解よりもコストの高い解を探す
² 有限で安全に探査可能な環境→完全性を保証
² 有限ではない場合→完全性を保証できない
まとめ
² 局所探索手法とメタヒューリスティック手法
³ 山登り法（Hill-climbing search）
³ 焼きなまし法（Simulated annealing）
³ 遺伝的アルゴリズム（Generic algorithm）
² オンライン探索
³ RTA*
³ LRTA*
人工知能
ゲームの理論
東京農工大学工学部知能情報システム工学科
藤田桂英
(katfuji@cc.tuat.ac.jp)
1
内容
² 二人完全情報確定的零和ゲーム
² ゲーム木と評価関数
² min-max法
² アルファ・ベータ法
² モンテカルロ木探索
³ Multi-armed Bandit
³ UCB (Upper Confidence Bound)
³ UTB (UCB applied Trees)
2
ゲームの分類
² 何人でするゲームか?
² 完全情報－不完全情報
² 確定的－非確定的
² 零和－非零和
何人でするゲームか
•
０人
– 鑑賞するだけ: ライフゲーム
•
１人
– 問題解決・パズル→探索が有効
•
２人←今回の対象
– 展開型ゲーム
– 囲碁、将棋、オセロ、五目並べ、・・・
•
３人以上
– 連合の余地が生まれる
– マージャン、ブリッジ、大貧民、・・・
– ジャンケンでの連合
完全情報－不完全情報
² 完全情報←今回の対象
³ 相手の状態がプレイヤーに見えている
³ 囲碁、将棋、バックギャモンなど
² 不完全情報
³ 相手の状態がプレイヤーに見えていない
³ ポーカー、マージャンなど
確定的－非確定的
² 確定的←今回の対象
³ ゲームの状態がプレイヤーの着手だけで決まる
³ 囲碁、将棋、マージャン（サイコロの部分を除く）
² 非確定的
³ 他の要因で状態が変化
³ バックギャモンなど
零和－非零和
• 零和（ゼロサム）←今回の対象
– 勝ちと負けとが存在し、プラスマイナスが０
– ほとんどすべてのゲーム
• 非零和（非ゼロサム）
– 勝ちだけ、または負けだけのようなことがあり、
全体の価値がプラスやマイナスになることがある
– 交渉、囚人のジレンマ
二人完全情報確定的零和ゲームを扱う
二人完全情報確定的零和ゲーム
² 自分と相手（敵）が交互に着手（指手）
² 局面：状態
² 着手：状態遷移
² 勝ち局面：ゴール状態
² 負け局面：ゴールでない終了状態
ゲーム木探索
• 局面をどんどん進めてみて、
それがどの程度良いかを判断
• 一般に、深く読むほど強くなる
探索木：OR木
10
木の葉= ゴールor 行き止まり
ゲーム木: AND/OR木
11
- 負け（●）を避け，勝ち（○）にたどり着きたい
- 最善手: 必勝手または少なくとも引き分けになる手
自分の手番
相手の手番
自分の手番
○
●
○
○
○
●
●
●
AND分岐
OR分岐
OR分岐
必勝手
ゲーム木とAND/OR木
² ゲーム木とAND/OR木の関係
³ 自分の手番では、勝ちに導く手をどれか選ぶ→OR分岐
³ 相手の手番では、相手がどの手を選んでも自分が勝つ
必要（すべての可能性を調べる必要）→AND分岐
12
C1
C3
C2
AND分岐
P
C1
C3
C2
OR分岐
すべての子問題（C1-C3）が
解ければ，Pが解ける
いずれかの子問題（C1-C3）が
解ければ，Pが解ける
P
ゲーム木の探索
² min-max法，αβ法
² モンテカルロ木探索，Multi-armed Bandit
13
○
自分
○
○
○
相手
○
○
○
○
○
○
自分
○
○○○
○
○
○○
○
○
100万
20万
1000
2000
1万
3万
4万
5000
3000
100
Win
Win   
Lose Lose
Lose
Lose
Win
Win
Lose
Win
評価関数
局面の評価値＝w1×(駒の損得)＋w2×(王の安全度)
＋w3×(駒の働き)＋w4×(手番)
・先読みをする最大の深さに達すると、その局面を評価
・評価関数が強さを大きく左右する
実際はもっと様々な
ものがある
局面評価関数の設計
² 最終的に勝ちそうか負けそうかを数値化
³ 勝ち: ＋∞, 勝ちに近い: ＋の数
³ 引き分け: ０
³ 負けに近い: －の数, 負け: －∞
² 将棋・チェス
³ (自分の駒価値の総和)－(相手の駒価値の総和)
³ 王の回りの駒価値を高くする
² 五目並べ
³ 石のならび（二、三、四、止まっているもの、飛び石）
³ （自分の並びの価値の総和）－（相手の並びの価値の総和）
² オセロ
³ （自分の石数）－（相手の石数）
³ （自分の可能手の数）－（相手の可能手の数）
³ （自分占有マス目価値の総和）－（相手占有マス目価値の総和）
演習問題1 交互ジャンケン
順番にジャンケンを出すゲームをする．
²
相手に勝つ手を出すと，自分にその指の本数分加点される．
²
負けた場合，あいこの場合，得点の変化はない．
²
自分がまず初期状態からパーを出した状態からスタート
²
（評価値）= （自分の得点）– （相手の得点）とする．
初期状態→相手→自分の一往復で終了する際のゲーム木は以下の通り．
ゲーム木の葉ノードに評価値を記入せよ．
min-max法
² 自分Aの手は局面が最良となる手を選択
³ AはBが最悪の手を打つと仮定してBの手を予測し，
Bの手から最良の手を選ぶ
² 相手Bは局面が（自分にとって）最悪となる手を選択
³ BはAが最良の手を打つと仮定してAの手を予測し，
Aの手から最悪の手を選ぶ
18
A
C
B
AND分岐
OR分岐
P
A
C
B
φ(A)
φ(B)
φ(C)
φ(A)
φ(B)
φ(C)
(minノード)
(maxノード)
φ(P)= min(φ(A), φ(B), φ(C))
P
φ(P)= max(φ(A), φ(B), φ(C))
min-max法の流れ
² 深さ制限探索に基づく評価値計算
³ ルートノードでは最大値を与えた手を選択
²
ボトムアップで評価値計算
min-max法の数学的表現
² solve(現在局面x) 
³ 現在局面から先読みしてその評価値を返す
solve(x) =
eval(x)  末端（評価関数の値）
max solve(y)  自分の手番
y := next(x)
min solve(y)  相手の手番
y := next(x)
演習問題2 min-max法
1. min-max法を適用し，A~Dの各ノードの評価値を求めよ．
2. このゲームに先手は勝つことができるか？
3. もし，最初の一手を先手が選ぶことができれば先手は勝つことができるか？
0
0
5
-2
-2
-2
0
2
0
Nega Max法
² チェスなどパスのないゲームで可能
² 相手手番のノード評価値の正負を逆転させる
³ 「相手は自分にとって損な手を探索する」→
「相手は相手にとって得な手を探索する」
*Solve() ,Eval() は手番側から見た値
Solve(x) =
Eval(x) 末端（評価関数の値）
max   (-Solve(y))   途中の場合
y:=next(x)
どのノードでも最大化となるので、探索部分の実装が簡単
Nega Max
ゲーム木探索アルゴリズム
Solve(スタート状態);  //Nega Max関数
入力x: 初期状態
int Solve(x){
if(xが末端) return Eval(x);
int max= -∞;
int w=0;
for(y in next(x)){
w= -Solve(y);
if(w>max)  max=w;
}
return max;
}
αβ法
² min-max法では盤面の局面を先読みすればするほど，
良い手を選択し，ゲームを有利に進めていく
² 探索しすぎるとゲーム木の探索空間が膨大になる．
² min-max法の性質を生かして，不必要な探索を避ける
ことが可能
² アルファ・ベータ法（αβ pruning）
³ βカット(β pruning) 評価値最小化局面の枝刈り
® 相手が評価値の大きな手を打たないことを利用して，
自分の行動を省略する
³ αカット(α pruning) 評価値最大化局面の枝刈り
® 自分が評価値の小さな手を打たないことを利用して，
相手の行動を省略する
βカット(β pruning)
² ノードxの評価値は4以上であるため，ノードAに
おける最小化にはノードxは寄与しない
26
A
3
x
3
2
4
y
評価済
評価の必要なし
φ(x)= max(4, φ(y))≧4
φ(A)= min(3, φ(x))=3
βカット(β pruning)
αカット(α pruning)
² ノードxの評価値は1以下であるため，ノードAに
おける最大化にはノードxは寄与しない
28
A
x
評価済
評価の必要なし
φ(x)= min(1, φ(y))≦1
φ(A)= max(2, φ(x))=2
2
y
3
1
2
αカット(α pruning)
演習問題3 αβカット
交互ジャンケンについてβカットをするエッジを求めなさい．
0
0
5
-2
-2
-2
0
2
0
コンピュータ囲碁
² コンピュータチェス、コンピュータ将棋と同様に
研究されてきた
³ ゲーム木探索、評価関数
³ 探索空間が膨大
³ 普通の評価関数を作るのが非常に困難
® 石の価値は平等
® 領域が確定するのはゲームの最後
® オセロのような明らかに特徴のある箇所が少ない
² モンテカルロ木探索による方法が出現
モンテカルロ木探索
² ランダムシミュレーション
³ プレイアウト：ランダムに着手を選んで終わりまで行う
³ 完全にランダムな場合
® 可能な着手を列挙して、その中から同確率で選ぶ
² 着手決定
³ 勝率の最も高いものを選択
² 評価関数が必要ない
Multi-armed Bandit
² N個の候補のなかから１個を選択する問題
² 得られる報酬の確率分布は台によって異なる
² なるべく期待値の高い台をプレイしたい
² 一定の回数のテストができる
³ テストするごとに資源が使われる
² 例
³ 複数のパチンコの台から、出る台を選択
³ 自転車通学で、早い経路の選択
² 候補を平等にテストするのは損
³ 良質な候補を多くテスト
探索（exploration）と
活用（exploitation）
² 探索: 現在知っている情報以外の情報を獲得するために
選択肢を選ぶこと
³ 行ったことがないレストランに行く
² 活用: 現在知っている情報から利益を最大化する選択肢
を選ぶこと
³ 行きつけのレストランに行く
² 探索と活用のトレードオフ
³ 探索優先: せっかく良い選択肢がどれか分かっているのに
選ばない
³ 活用優先：現状でベストな選択肢より良い選択肢があっても
気付かない
² Multi-Armed Banditアルゴリズムで解決
UCB(upper confidence bound)
² UCBスコアが最大の台をプレイ
³ 選択肢についてどれだけ知っているかを考慮
³ 知らない選択肢について、積極的に探索
² 勝率が高く，プレイアウト回数が少ない手を選ぶ
各テストの期待値（活用）
ボーナス（探索）
𝑤!,#
𝑛!,#
+ 𝑐2 log 𝑡
𝑛!,#
𝑤!,#: t 回目の着手iでの勝利数
𝑛!,#: t 回目の着手iを選んだ回数
c: パラメータ
UCT(UCB applied Trees)
² UCB+モンテカルロ木探索
³ UCB値の高い候補により多くの
プレイアウトを割り振る
² 末端でのプレイアウト回数が
閾値以上→その手を展開
² UCB値が高い手からプレイ
アウト→浅い読みで良さそうな手
を優先的に深く探索
² 探索回数が大きくなるにしたがい、
結果が期待値に収束する
左のノードが閾値以上
左のノードを展開
まとめ
² 二人完全情報確定的零和ゲーム
³ 将棋，囲碁，チェスなど
² ゲーム木と評価関数
³ AND/OR木
² min-max法
² アルファ・ベータ法＝αカット, βカット
² モンテカルロ木探索
³ Multi-armed Bandit
³ UCB (Upper Confidence Bound)
³ UCT (UCB applied Trees)
38
人工知能
確率と不確実性
東京農工大学工学部知能情報システム工学科
藤田桂英
(katfuji@cc.tuat.ac.jp)
1
内容
² 環境の不確実性
² 確率の基礎
² ベイズの定理
² 期待値と意思決定
² 確率分布のパラメータ推定
³ 最尤推定、ベイズ推定
2
実世界の不確実性と確率
² 実世界の不確実性
³ 実世界とコンピュータ・シミュレーションの世界の違い
® 例）ボールの放物運動, 画像認識やパターン認識、
電子メールにおけるスパムメールなど
² ベイズ理論(Bayes’ theory)
³ ベイズの定理を活用し、確率論の枠組みに基づき、
データからの推定や決定、解析を行う
3
事象と確率
² 何かが生じる確からしさを扱いたい
³ 事象(event) = 何か
® ある事象: A
³ 確率(probability) = 確からしさ
® 確率を与える関数: P(・)
あるロボットの動作100回の履歴
,    0 ≦P(A) ≦1
P(“結果:前進”)=32/100
P(“結果:停止”)=68/100
P(“命令:前進”)=28/100
P(“命令:停止”)=72/100
4
同時確率(joint probability)
² 事象A と事象B がともに起こる確率
³ P (“命令：前進”, “結果：前進”) =  20/100
² 重要な定理
³ P(A,B) = P(B,A)
³ P(A,B) = P(A∩B)
5
加法定理(additional theorem)
² 事象A と事象B の少なくともどちらか一方が生じる事象
→A ∪B
² 加法定理: P(A ∪B) = P(A) + P(B) - P(A∩B)
³ P (“命令：前進” ∪“結果：前進”) = P (“命令：前進” ) + 
P (“結果：前進”) - P (“命令：前進” ,“結果：前進”) 
= 28/100 + 32/100 - 20/100 = 40/100
² 事象A と事象B が排反の場合（つまりP(A∩B) = 0）
³ P(A ∪B) = P(A) + P(B)
6
条件付き確率(conditional probability)
² 事後確率(posterior probability): P(A|B)
³ 事象Bが起こったことがわかっている場合、
事象Aが起こる確率
P(A|B) = P(A,B)/P(B)
² P(“結果：前進”|“命令：前進”) = 20/(20+8)
7
乗法定理(multi-tiplication theorem)
² 同時確率P(A,B)と条件付き確率P(A|B)の関係
P(A,B) = P(A|B)P(B)
² （左辺）= P(“結果：前進”,“命令：前進”) =20/100 =1/5
² （右辺) = P(“結果：前進”|“命令：前進”) * P(“命令：前進”) 
= 20/28 * 28/100 = 1/5
8
周辺化(marginalization)
² 同時確率P(A,B)において、一方の事象について全て
の可能性を足し合わせて、その変数を消去する
P(“命令：前進”) 
= P(“命令：前進”,”結果：前進”) + P(“命令：前進”,結果：停止”)  
= 20/100+8/100 = 28/100
9
演習1
² ２つの袋があり、皮の袋が2/3の確率で選ばれる。布の袋
が1/3の確率で選ばれる。それぞれの袋には下記の玉が
それぞれ入っており、袋が選ばれるとその後は全ての玉
が等確率で取り出される。以下を求めよ。
1.
P(X1)
2.
P(Y2|X2)
3.
P(X1,Y2)
4.
P(Y1)
Y1 : 赤玉
Y2 : 青玉
Y3 : 黄玉
X1 : 皮の袋
15個
5個
0個
X2 : 布の袋
15個
1個
4個
10
ベイズの定理の導出
² 条件付き確率の性質から自然と導かれる基本的な式
条件付き確率の性質
よく使われる式（周辺化+乗法定理の逆）
12
ベイズの定理の意味
² ある事象が起こりその原因としていくつかの事象が考えられる
³ 原因は互いに独立な事象、それぞれがある確率をもって起こる（不確実）
² ベイズ理論の捉え方
³ 結果としての事象に対する原因がどれであったかという確率を求める
® グラウンドが濡れている←朝に雨が降った、グラウンドに水まきをした
³ Bが生じる確率（P(B)）に関して、新しい情報Aを得た時のBの生じる確率
（P(B|A)）
® ロボットが距離センサなどの情報Aを新たに取得→自分の状態Bを推定
非常に柔軟な枠組みであり，機械学習，自然言語処理，パターン認識，
音声認識はじめ，多くのデータを扱う情報処理で一般的に用いられる
B
A
原因
結果
P(B|A)
P(B)
P(B|A)
情報Aがない時の
状態B
情報Aを得た時の
状態B
情報Aを観測
A
13
隠れた事象の推定とベイズの定理
例えば，C = {C1, C2, . . ., CK} のいずれかの事象が生じる場合を考える．
² 尤度（ゆうど）: 仮説もしくは前提の尤もらしさを表す値
² 事象Cjを前提とした時に、観測された事象Aが出てきやすい
→ 事象Cjは前提として尤（もっと）もらしい
14
演習2
² ２つの袋があり、皮の袋が2/3の確率で選ばれる。布の袋が1/3の
確率で選ばれる。それぞれの袋には下記の玉がそれぞれ入って
おり、袋が選ばれるとその後は全ての玉が等確率で取り出される。
以下の問いに答えよ。
1.
P(X1|Y1)を求めよ
2.
P(X2|Y1)を求めよ
3.
赤い玉が取り出された時，取り出した袋はどちらだった
可能性が高いか？
Y1 : 赤玉
Y2 : 青玉
Y3 : 黄玉
X1 : 皮の袋
15個
5個
0個
X2 : 布の袋
15個
1個
4個
15
確率変数と期待値
² 事象Aが生じる確率: P(A)
² 事象Aが決まった際に何らかの値を返す関数: f(A)
17
期待値: 
² ロボットが前に進む距離（前進:10, 停止:0）の期待値
³ 事象Aに対して前進する距離をf(A)として
= 10*(0.8*0.3+0.4*0.7) + 0*(0.2*0.3+0.6*0.7) = 5.2
条件付き期待値(conditional expectation)
² その行動を起こした際に得られる利得の期待値の最大化、もしくは
リスクの最小化→選ぶべき行動
18
条件付き期待値
ロボットがB=“命令:前進”を選択した場合の移動距離の条件付き期待値
ロボットがB=“命令:停止”を選択した場合の移動距離の条件付き期待値
“命令|前進”を選択した方がいい
[前に進む距離] 
•
前進:10
•
停止:0
決定理論(decision theory)
² 意思決定における価値、不確かさといった事柄を数学的
かつ統計的に確定→最善の意思決定を導き出す理論
³ 十分な情報を持つ理想的な意思決定者を仮定
= 完全な正確さで計算し、合理的に意思決定する
² 規範的手法を現実の人間の意思決定に応用する
→意思決定支援システム
² 選択におけるパラドックス→ゲーム理論
³ ある人の意思決定に他の人が反応して、それぞれが
意思決定する
19
演習3
² ２つの袋があり、皮の袋が2/3の確率で選ばれる。布の袋が1/3の
確率で選ばれる。それぞれの袋には下記の玉がそれぞれ入って
おり、袋が選ばれるとその後は全ての玉が等確率で取り出される。
² 取り出した玉が赤玉なら1点、青玉なら2点、黄玉なら3点。
² 皮の袋から取り出したことがわかっている場合、玉を一つ取り出し
た場合得られる得点の条件付き期待値を求めなさい。
Y1 : 赤玉
Y2 : 青玉
Y3 : 黄玉
X1 : 皮の袋
15個
5個
0個
X2 : 布の袋
15個
1個
4個
20
確率分布の推定
² パラメータ推定: ある確率分布を仮定しそのパラメータθ
を推定すること
³ 正規分布→θ1=平均値, θ2=分散がパラメータ
³ 多項分布/カテゴリカル分布（K種類のいずれかの確率）
→各種xが出る確率θx がパラメータ
® K=2の場合はベルヌーイ分布（二項分布）と呼ぶ
22
最尤（さいゆう）推定
² 確率分布のパラメータ推定に用いられる手法の一つ
² 得られた観測に対し最も尤もらしいパラメータを求める
（尤度の最大化、最小化）
23
パラメータθで定まる確率分布P(x|θ）に対して
観測: 
尤度: 
パラメータθがどれくらいXが観測される分布として尤もらしいかに着目
→θの最尤推定値(maximum likelihood estimator: MLE): θMLE
²
パラメータμの最尤推定
³ 対数尤度l(μ)=log P(m|μ) の最大化を行う
24
微分すると
l’(μ)=0 の場合
μ : 1-μ = m : N-mのとき、μMLE = m/N （最尤推定値）
結果が前進だった時の頻度の割合が最尤推定値
ロボットが命令により前進する確率: μ
合計N回の試行で前進した回数: m
（二項分布より）
【ロボットの例】
確率は？
ベイズ推定(Bayesian inference)
² パラメータも他の変数と同じように確率変数と捉えて、
ベイズ推定の枠組みによって求める
² 偶然観測されなかった事象の確率を過小評価するのを防ぐ
25
パラメータθの確率分布を事前確率P(θ)と定義
観測
の後のθの事後分布は
P(θ|X)を最大化するθ=θMAPを求める
→最大事後確率(maximum of posteriori: MAP)推定
最尤推定との違い
² 観測された情報から厳密な確率分布P(θ|X)を求めるのは難しい
→近似的に推論（変分ベイズ推論、マルコフ連鎖モンテカルロ法、
量子フィルタなど）
まとめ
² 環境の不確実性
² 確率の基礎
² ベイズの定理
² 期待値と意思決定
² 確率分布のパラメータ推定
³ 最尤推定、ベイズ推定
26
人工知能
確率的生成モデルと
ナイーブベイズ
東京農工大学工学部知能情報システム工学科
藤田桂英
(katfuji@cc.tuat.ac.jp)
1
内容
² 確率的グラフィックモデル
² マルコフ決定過程
² ナイーブベイズモデル
³ スパムメールフィルタの例
² 隠れマルコフモデル
³ 尤もらしい形態素解析
2
確率システムの表現
² 確率システム: 次状態が現在の状態と行動
に依存して確率的に決定するシステム
³ 確率システムの場合は状態遷移則が確率的に
なるため関数での表記が不可能
³ 確率分布による表現を用いる
状態遷移則（離散）
3
確率モデルと確率生成モデル
² 確率モデル(probabilistic model): 
確率変数とその関係性に基づき対象を表現するモデル
³ 対象システムにどのような変数があるのか？
³ 対象システムの変数間にどのような関係にあるのか？
² 確率的生成モデル(probabilistic generative model):
様々な確率変数がどのように影響を与えながら
その値を決めていくのか
4
確率的グラフィカルモデル
² ノード（○）:確率変数
² 有向辺（→）:確率変数の依存関係
5
確率変数の依存関係と独立
a.
確率変数が依存関係
³
ロボットが行動する時の
命令:X, 結果:Y のときの関係
6
b.
確率変数が独立
³
２つのサイコロがあり、
サイコロ1の目: X
サイコロ2の目: Y
【生成過程】
右の確率分布から左の確率変数の値を引き出す
乗法定理
XとYが独立
観測とプレート
² 健在変数（観測変数）: 観測できる変数（○）
² 潜在変数（隠れ変数）: 観測できない変数（●）
² プレート表現: プレート上の確率変数をN回
繰り返してサンプリングする(ループ分ブロック）
7
X∈{“命令:前進”, “命令:停止”}
Yn ∈{“結果:前進”, “結果:停止”}
ロボットが同じ命令Xを
N回実行した際のn回目の実現値
健在変数
（観測可能）
潜在変数
（観測できない）
ノードの関係性
² 確率変数のつながり方は3通り
³ head-to-tail: P(X,Y,Z)=P(Y|Z)P(Z|X)P(X)
³ tail-to-tail: P(X,Y,Z)=P(Y|Z)P(X|Z)P(Z)
³ head-to-head: P(X,Y,Z)=P(X)P(Y)P(Z|X,Y)
8
head側
親ノード
tail側
子ノード
² head-to-tail: P(X,Y,Z)=P(Y|Z)P(Z|X)P(X)
³ 伝承サンプリング
³ Yをサンプリングする場合を考える
1.
P(X)をサンプリング
2.
1のXに基づいてP(Z|X)からZをサンプリング
3.
2のZに基づいてP(Y|Z)からYをサンプリング
² tail-to-tail: P(X,Y,Z)=P(Y|Z)P(X|Z)P(Z)
³
ZがXからYの経路をブロックする
®
Yの確率はXに全く依存しない
² head-to-head: P(X,Y,Z)=P(X)P(Y)P(Z|X,Y)
³
Zが観測されることでXとYに依存関係が生まれる
9
条件付き独立（Zが与えられた時，XとYは独立になる）
ベイズの定理
マルコフブランケット
² 確率モデルの式変形を行う際、
どこまでの変数を無視してよいか
マルコフブランケット
(Markov blanket): ∂A
= ノードAの親と子、および子の親
B: ノードAと∂Aを除いた集合
ノード集合Bに含まれる確率変数はAと条件付き独立
= P(A|∂A)の評価時にはBを無視してもいい
10
マルコフ過程
² マルコフ性: ある変数が１ステップ前の変数のみに
影響をうけて，確率的に変化する性質
11
s1, s2,…, st（時刻t までの全事象の系列)
² マルコフモデル: マルコフ性をもつ遷移モデル
² マルカフ連鎖: マルコフモデルにより生成される
状態遷移系列
再帰的な伝承サンプリングst+1〜P(st+1|st)により次状態を決定していく確率生成過程
※ 直前のn個の状態が次の状態遷移に与えるモデル= n次マルコフモデル
状態遷移確率
² 離散での状態遷移確率
² 3状態での状態遷移確率行列
12
マルコフ決定過程(MDP)
行動atに依存して状態st+1が決まっていく確率システム: 
P(st+1| st,at)
13
行動選択に依存した状態遷移確率
² 行動として，A = {“stop”,“move”} の2 種類があり
at = “stop” の際にロボットは動かないとする
14
状態行動atを選択した際に，次の時刻での各状態st+1の
存在確率P(st+1)は乗法定理と周辺化から
15
時刻tにおける状態stのあらゆる可能性を考慮して，
それぞれの状態遷移に関する確率を足し合わせている．
状態が♯(S)個あるとして，すべての状態に関する存在確率P(st)を
列ベクトルとして並べたものをp(st)=(P(st=1), P(st=2),…,P(st=♯(S))T
i行j列の要素がpi,j,a_t=P(st+1=i| st+1=j,at)である状態遷移確率: 
行動at に関しても周辺化されるので，
st+1に関する確率分布
ナイーブベイズモデル
² 生成モデルに基づき分類を行うための最も単純なモデル
² 観測データが生成される過程を，生成モデルのナイーブベイズ
モデルによってモデル化し，潜在変数zを推定する分類を行う
→ナイーブベイズフィルタ
² 分類問題(classification)
³ 入力ベクトルに対して二値{1,0}の値を返すことで分類を行う
³ 学習データとしては正負のラベルの付けられたデータセットを用いる
16
？
X
Y
正事例
負事例
x1
x2
様々な(x, y) 上の点が与えられた時に
未知の入力に対する出力y を答える
スパムメールのナイーブベイズフィルタ
² メールがスパムメールかどうかを判定する分類問題
問：メールに「お得」「銀行口座」が含まれていたときのスパムメール確率は？
推定の対象とはせずに外生的に決定されるパラメータ
ナイーブベイズのグラフィカルモデル
17
² あるメールに「お得」「銀行口座」が含まれている確率
18
P(z=1)=0.9
P(z=0)=0.1
ベイズの定理
※θは省略
スパムメールである確率が，スパムメールでない確率より27倍ほど大きい
隠れマルコフモデル(HMM)
² 単純なマルコフ連鎖
³ 状態は直接観測可能= 状態の遷移確率のみがパラメータ
² 隠れマルコフモデル
³ 状態は直接観測されず出力（事象）のみが観測される
= 遷移確率と出力確率（分布）の2種類がパラメータ
19
確率変数x(t): 時刻t における潜在変数
確率変数y(t): 時刻t における観測値
矢印: 条件付き確率間の依存関係
² 観測値系列の確率の推測
³ モデルのパラメータが既知→特定の出力系列が得られる確率
20
² 潜在変数の確率の推測
³ フィルタリング
³ 平滑化
³ 最尤系列推定
® ビタビアルゴリズム: モデルパラメータが既知のとき、
与えられた配列を出力した可能性（尤度）が最も高い状態列
（最尤状態列）を計算するアルゴリズム．動的計画法の一種
長さLの観測値系列
潜在状態系列
可能な状態系列についての確率の総和によって計算
隠れマルコフモデルによる
尤もらしい形態素解析
21
形態素の範囲
² 自立語: 名詞，動詞，形容詞など
³ りんご，食べる，おいしい
² 付属語: 助調，助動調など
³ 私はりんごを食べたい
² 活用語
³ 食べ(活用語幹)+る(活用語尾)
² 派生語
³ 美し(派生語基)+さ(接尾辞)
² 複合語
³ うれし（名詞）+涙（名詞），本（名詞）+棚（名詞）
22
形態素解析
² 形態素への分割(segmentation)
² 品詞付与(part of speech tagging)
³ 品詞語のカテゴリ(e.g. 名詞，動詞，形容詞)
² 解析例
³ すもももももももものうち
³ 分割→すもも/も/もも/も/もも/の/うち
³ 付与→名詞/助詞/名詞/助詞/名詞/助詞/名詞
23
尤もらしい形態素解析
² 確率をベースに品詞の接続の強さを測る= コスト
² 入力単語の列に対して尤もらしい品詞列を与える問
題と考える
² 尤もらしさの尺度
³ 各語について，複数の品詞がありうる場合，どの品詞が
尤もらしいか
³ 品詞の並びによる優先度
® 例：「The」の後に来る語は名詞の確率が高い
隠れマルコフモデル(HMM)を活用
「システムがパラメータ未知のマルコフ過程である」と仮定し、
観測可能な情報からその未知のパラメータを推定
24
尤もらしい形態素解析の流れ
² 品詞付与された解析済みコーパスに以下を付与
³ 単語の出現のしやすさ
³ 品詞(単語)のつながりやすさ（確率値）
² 文を構成する単語の出現確率が直前のn-1 語にのみ
依存すると仮定（マルコフ性）
² 目的:最大の出現確率をもつ品詞列を求める
= 単語の出現確率や品詞の連接確率の積が最大に
なるような品詞列を求める
25
記号の定義
26
入力と目的関数
² 入力文(w1,n=w1,w2,…,wn) -> 各単語の品詞(s1,n=s1,s2,…,sn)
² 目的関数: 入力文に対して生起確率が最大となる品詞列
※ s0 およびsn+1 は、文頭および文末を表す特別な品詞
入力文が与えられた時に、品詞が
s0,n+1 である確率
(条件付確率の定義)
(P(w1,n)は定数)
(ベイズ定理)
27
前の式のそれぞれの項を以下のように簡単化する
（マルコフ性を活用）
28
確率値の計算の例
29
確率値の計算例
² 単語の生起確率
³ 例えば、「学校」という名詞がコーパス中に３０回現れたとする
³ また、コーパス全体に現れる名詞の総数を１００００回とする。
このとき、「学校」の名詞としての出現確率は、
² 品詞の連接確率
³ 例えば、コーパス中に名詞が１００００回出現し、その直後に格助
詞が３０００回出現したとする
このとき、名詞と格助詞の連接確率は、
003
.
0
10000
30
)
(
,
(
)
|
(
=
=
=
名詞
名詞）
学校
名詞
学校
C
C
P
3
.
0
10000
3000
)
(
,
(
)
|
(
=
=
=
名詞
格助詞）
名詞
名詞
格助詞
C
C
P
30
確率値から対数値へ変換
² 確率を直接扱うと全体の生起確率が非常に小さい値
になる(=アンダーフローを起こす可能性)
² 確率値の対数をとる
² 結果として得られるのは、対数値の和の最小化問題
31
最良パスの求め方（動的計画法）
文頭
くるま
名詞
２５００
700
くる
動詞
カ変（基本）
４５０
2700
くる
動詞
五段（基本）
３０００
2700
で
格助詞
０
1000
4500
4200
5700
3150
3200
まで
格助詞
０
1400
1400
で
助動詞
（連用）
０
1300
7100
4550
目的関数:
32
「くるまでまつ」
文頭
くるま
名詞
２５００
700
くる
動詞
カ変（基本）
４５０
2700
で
格助詞
０
1000
4500
4200
5700
3150
3200
まつ
動詞
五段（基本）
１９００
800
まで
格助詞
０
1400
くる
動詞
五段（基本）
３０００
2700
1400
で
助動詞
（連用）
０
1300
800
6900
7250
4550
1500
7900
目的関数:
最良パスの求め方（動的計画法）
33
「くるまでまつ」
文頭
くるま
名詞
２５００
700
くる
動詞
カ変（基本）
４５０
2700
で
格助詞
０
1000
4200
5700
3150
3200
まつ
動詞
五段（基本）
１９００
800
1400
くる
動詞
五段（基本）
３０００
2700
1400
1300
6900
4500
まで
格助詞
０
で
助動詞
（連用）
０
800
4550
1500
まつ
名詞
２５００
600
600
7300
8200
7650
1200
目的関数:
最良パスの求め方（動的計画法）
34
「くるまでまつ」
文頭
くるま
名詞
２５００
700
くる
動詞
カ変（基本）
４５０
2700
で
格助詞
０
1000
4200
5700
3150
3200
まつ
動詞
五段（基本）
１９００
800
1400
くる
動詞
五段（基本）
３０００
2700
1400
1300
6900
4500
まで
格助詞
０
で
助動詞
（連用）
０
800
4550
1500
まつ
名詞
２５００
600
7300
600
1200
960
文末
500
7400
8260
目的関数:
最良パスの求め方（動的計画法）
35
「くるまでまつ」
文頭
くるま
名詞
２５００
700
くる
動詞
カ変（基本）
４５０
2700
で
格助詞
０
1000
4200
5700
3150
3200
まつ
動詞
五段（基本）
１９００
800
1400
くる
動詞
五段（基本）
３０００
2700
1400
1300
6900
4500
まで
格助詞
０
で
助動詞
（連用）
０
800
4550
1500
まつ
名詞
２５００
600
7300
600
1200
960
文末
500
7400
目的関数:
最良パスの求め方（動的計画法）
36
「くるまでまつ」
文頭
くるま
名詞
２５００
700
くる
動詞
カ変（基本）
４５０
2700
で
格助詞
０
1000
4200
5700
3150
3200
まつ
動詞
五段（基本）
１９００
800
1400
くる
動詞
五段（基本）
３０００
2700
1400
1300
6900
4500
まで
格助詞
０
で
助動詞
（連用）
０
800
4550
1500
まつ
名詞
２５００
600
7300
600
1200
960
文末
500
7400
目的関数:
最良パスの求め方（動的計画法）
37
「くるまでまつ」
まとめ
² 確率的グラフィックモデル
² マルコフ決定過程
² ナイーブベイズモデル
³ スパムメールフィルタの例
² 隠れマルコフモデル
³ 尤もらしい形態素解析
38
人工知能
強化学習
東京農工大学工学部知能情報システム工学科
藤田桂英
(katfuji@cc.tuat.ac.jp)
1
内容
² 強化学習とは何か？
² 強化学習の理論
² 価値関数
² Q学習
² 強化学習の発展とその分類
2
試行錯誤の中での学習
² 試行錯誤を通した学習= 強化学習
³ やってみては、その結果・評価を観察し、
徐々に「やり方」を改善していく
® サッカーのフリーキック，ボーリング etc.
スタート位置，
⾜の動かし⽅
⼿の振り上げ⽅
⽅向 etc.etc….
倒れた本数
フィードバック
オペラント条件づけ
² 自発的な試行錯誤の結果として得られる報酬に
よって行動形成がなされること
→オペラント条件づけ
³ スキナー箱(Skinner 1938):主としてラットやハトの
オペラント条件づけや行動研究に用いる実験装置
4
ハトはスイッチを押して餌を食べることを学習していく
強化：その行動を
とりやすくなること．
方策と価値，報酬
² 方策(policy)
³ ある状態にいたときに、どういう行動をどれくらい
の確率で選択するか
² 価値関数(value function)
³ 状態や行動の価値
² 報酬(reward)
³ 即時報酬、遅延報酬、累積報酬
強化学習は「経路」を求めることが問題ではなく、
方策/価値関数を求めることが目的
² s1, s2, s3: 状態（台の上のどこにいるか？）
² a1, a2, a3: 行動（右/左に行く，つつく）
² π(s,a)=P(a|s): 学習すべき方策
³ 状態と行動の組み合わせごとに行動価値を記憶する表を作成
6
強化学習理論
² 試行錯誤による学習をAIにさせる=強化学習
³ 確率システムとして問題をモデル化
³ 状態と行動を事前に定義
³ 報酬と罰（負の報酬）を受け取ることで学習を進め
報酬を改善
® 情報を得ながらの学習（オンライン学習）を仮定
® 即時報酬だけではなく、累積報酬（将来にわたって
得られる報酬の和）を最大化することが重要
³ 行動価値の表を更新することでより多くの報酬を
得るための行動が学習できる
7
状態遷移確率と報酬関数
² 強化学習はマルコフ決定過程(MDP) により定式化
² 方策(policy)
³ 将来にわたり得られる報酬の期待値を最大化する方策を発見
→最適方策
³ γ (0 ≤ γ < 1) : 割引率(discount rate)
³ 将来にわたって得られる報酬の和になっているが、
遠い未来であればあるほど割り引いて換算
³ γ=1 では T→∞で発散する（累積報酬と同じ）
割引累積報酬
² 累積報酬の最大化→いつまでもゴールしない
状況で報酬が発散してしまう
² 割引累積報酬(discounted return):  Rt
割引率と未来の報酬価値
演習1 割引累積報酬の計算
²
CとEはゴール状態，矢印の数字は即時報酬の値
²
方策１は「右へ行けたら右、右にいけないならば上」
²
方策２は「上へ行けたら上、上に行けないならば右」
³ 両方行けない場合はその場にとどまる
²
割引率γ= 0.5 の時のA,B,C,D,Eの状態において、方策１、方策２に従う場
合、それぞれの状態からゴールにおける割引累積報酬の値を求めよ。
A
B
D
E
C
1
2
0
3
0
0
A
B
C
D
E
方策１
方策２
演習2 割引累積報酬の計算
²
CとEはゴール状態，矢印の数字は即時報酬の値
²
方策１は「右へ行けたら右、右にいけないならば上」
²
方策２は「上へ行けたら上、上に行けないならば右」
³ 両方行けない場合はその場にとどまる
²
割引率γ= 1 の時のA,B,C,D,Eの状態において、方策１、方策２に従う場合、
それぞれの状態からゴールにおける割引累積報酬の値を求めよ。
A
B
D
E
C
1
2
0
3
0
0
A
B
C
D
E
方策１
方策２
状態価値関数
² よりよい方策を学習する
→正しく状態と行動の価値を見積もる必要
² 状態価値関数
³ 「その方策π に従えば，その状態s からスタートして
将来にどれだけの割引累積報酬を得られるか」
Eπ : 行動at の決定に方策
を用いた際の期待値
S→A: 0.1
S→B: 0.1
S→C: 0.8
割引率γ=0.9
経路
確率
報酬
割引累積報酬
S→C→E→・・・
0.8
0→3→0→・・・
2.7
S→B→・・・
0.1
1→0→・・・
1.0
S→A→・・・
0.1
2→0→・・・
2.0
ベルマン方程式
現状態の状態価値を次の報酬と次状態の価値だけで再帰的に定義
A
S
C
E
B
1
2
0
3
0
0
F
?
?
気にしない！
Vπ(S)
Vπ(C)
Vπ(B)
Vπ(A)
rt+1
行動価値関数
² 行動価値: 状態s において行動a をとった後
に方策πに従う場合に得られる報酬の期待値
² 行動価値Vπと行動価値関数Qπの一般的な関係
² 最適行動価値関数は
行動価値関数のベルマン方程式
² ベルマン方程式に基づき強化学習の問題を
解く様々な手法が提案されている
³ 例）SARSA, アクタークリティック法，Q学習など
Q学習
² 最適行動価値関数Q*(s,a)の値= Q値
² オンライン学習により実現
³ AIを動かしている間に少しずつ進めていく
³ オフライン学習: データを全て集めてきた後に，
まとめて学習する
20
【ベルマン方程式】
方策は最適方策π*に従う→a’ も最適な行動
（次ステップ以降の行動価値が最大化されるものだけ選ぶ）
² すべての(s,a) に対してQ(s,a)を記憶するテーブルを準備
² もし，st, at に対して必ずst+1に遷移するのであれば，
21
しかし，実際はst, at, st+1の確率的な状態遷移からの1サンプルにすぎない，
学習中のQ値では収束していない→0にならずに誤差が残る（TD誤差）
TD誤差
以下の更新式に基づいてQ(s,a)を少しずつ更新していく→Q学習
学習率, 0<α≦1
（平衡状態へ近づけていく勢い）
Q学習のアルゴリズム
方策による
行動選択
報酬と状態
の観測
Q値の更新
Q学習の行動選択の方策
² ランダム法: 全ての行動を等確率で選択
² グリーディ法: 各状態において最適と思われる行動を選択
² ε-グリーディ法: 確率εでランダムに行動を選択肢，
確率(1-ε)でグリーディ法を行う
² ボルツマン選択: パラメータT により exp(Q(s,a)/T)に比例した
確率で行動選択を行う
³ Tが大きくなればランダム法，Tが小さくなればグリーディ法に近づく
14:20
演習3 Q学習の1-stepを追う
行動at
Q値
右
8
左
10
停止
5
St
St+1
行動at
Q値
右
10
左
8
停止
5
rt+1=4
select
エージェントは状態Stで行動「右」をとった結果St+1に遷移した。
それぞれの状態での現在の学習中の行動価値の値は表のとおりである。
割引率は0.9とする。
1. TD誤差δtはいくらか？
2. この1stepで表において、どのQ値がどれだけ変わるか？
学習率αを0.5として示せ。
モデルベースとモデルフリー
² モデル=環境と報酬
² モデルベース強化学習: 学習アルゴリズムが明示的に
環境のダイナミクスと報酬関数をモデル化
³ モデルは機械学習により推定or 外部から与えられる
³ サンプル効率が高い
³ ロボットや自動運転車への適用には向いている
² モデルフリー強化学習: モデルを明示的にモデル化しない
³ 代表例: TD学習，Q学習
³ 最終的な性能はいいが、サンプル効率が低い
³ 際限ない回数の試行が可能なゲームAIやシミュレーション
空間内でのロボット学習に向いている
26
価値ベースと方策ベース
² 価値ベース: 行動価値関数Q(s,a)を求めて
その行動価値の比較により各状態における行動を
決定（方策を求める）
³ Q学習
² 方策ベース: 直接、方策関数π(s,a)を求める
³ アクタークリティック法（状態価値関数V(s)は求める）
³ 方策勾配法（状態関数すら求めずに方策のみを改善）
27
on-policy とoff-policy
² on-policy: 未来の行動が現方策に従って選ばれる
と想定して学習
³ 必ずしも最善策をとるとは限らない前提で学習を行う
³ 方策Π1を用いたサンプルは方策Π2の改善に用いない
³ SARSAなど
² off-policy:未来の行動が現方策に関係なく常に
最善のものが選ばれると想定して学習
³ どのような方策を用いて得たサンプルであっても方策の
改善に用いる
³ Q学習など
28
状態表現学習と深層強化学習
² 多くの強化学習手法→MDPを前提としている
² 状態s をどのように設計し、表現するかは難しい
→深層強化学習（DQN）
29
ゲームの画像情報を入力として，
DQNによってAtariをプレイする
ゲームAIを実現
•
画像sを入力としたNNを準備
•
行動aごとの行動価値を
関数近似により学習
まとめ
² 強化学習とは何か？
² 強化学習の理論
² 価値関数
² Q学習
² 強化学習の発展とその分類
30
人工知能
命題論理と述語論理
東京農工大学工学部知能情報システム工学科
藤田桂英
(katfuji@cc.tuat.ac.jp)
1
内容
² 記号論理
² 命題論理
² 述語論理
² 節形式
2
記号論理
² 自然言語や事象を記号に変換したものを，その
論理関係によってとらえる(Symbolic logic)
³ 数学: 記号+数式, 記号論理: 記号+論理式
³ 命題論理(propositional logic), 述語論理
(predicate logic), その他の派生論理
® 様相論理，時制論理，ファジィ論理，etc.
² 物事の「真・偽」だけを論理的に扱う世界
² 自然言語⊃・・・・・⊃述語論理⊃命題論理
² 数学の公理系⊃・・・・・・⊃述語論理⊃命題論理
命題論理（Propositional Logic)
² 論理定数：True(T), False(F)
² 素式: 基本命題を表す記号(p, q, r …)
² 論理記号: 命題と命題を結合する記号
（例）昼であるか曇っていれば星は見えない
= 昼であるまたは曇っているならば星が見えない
= (p V q) →￢r
4
同値
等しい
EQUIV
含意
ならば
IMPLY
否定
ない
NOT
選言
または
OR
連言
かつ
AND
¬
Ú
Ù
⇒
⇔
論理記号一覧
p
q
r
論理式の意味
² 論理記号と論理定数の解釈を規定
=論理式が「True」なのか「False」なのか
² p∧q, (p∨q), (p⇒q), (p⇔q)の論理的意味
5
T
T
F
F
F
F
F
T
T
F
T
F
F
F
T
F
F
T
T
T
T
T
T
T
p ⇔q
p ⇒q
p ∨q
p∧q
q
p
論理式の解釈
1.
論理式を構成している素式の真偽をそれぞれ判定
2.
論理記号間の結びつきを考える
3.
元となる論理式全体の真偽を決定
→真理値表（素式の真偽のあらゆる組み合わせに対す
る論理式の解釈を表形式にまとめたもの）が有効
6
p
q
￢p V q 
T
T
T
T
F
F
F
T
T
F
F
T
論理式￢p V q の真理値表
論理式の同値関係
² 二重否定￢（￢ｐ）=ｐ
² べき等律p∨p=p，p∧p=p
² 補元律p∨￢p=T，p∧￢p=F
² 交換律p∨q=q∨p，p∧q=q∧p
² 結合律（p∧q）∧r=p∧(q∧r)，
(p∨q)∨r=p∨(q∨r)
² 分配律p∨(q∧r)=(p∨q)∧(p∨r)，
p ∧(q ∨r)=(p ∧q) ∨(p ∧r)
² ド・モルガンの法則￢(p∧q)=￢p∨￢q,￢(p∨q)=￢p∧￢q
² 恒真式p∨T=T，p∧T=p
² 恒偽式p∨F=p，p∧F=F
² 含意の除去p→q=￢p∨q
² 同値記号の除去
（p=q）=((p→q)∧(q→p))
演習1   命題論理
² 下の真理値表を完成させよ．
p
q
￢p∨q
p→q
￢(q→p)
p∧￢p
T
T
T
F
F
T
F
F
命題論理式の節形式への変形
² 命題論理式
³ 基礎となる素式をp,q,r などの記号で表現
³ 素式を論理記号で結合することによって得られる論理式
² 同値となる論理式は多数→標準形を定めておく必要
³ 多項式における因数分解，展開のイメージ
² 連言標準形（和積標準形：conjunctive normal form）
³ リテラル(literal): 素式，または素式の否定
³ 節(close): リテラルの論理和のみからなる論理式
³ 節形式(closed form): 節の論理積のみからなる論理式
リテラル
節
節形式
論理式の節形式への変換
1.
同値記号=と含意記号→を以下の同値関係を
用いて除去する．
³ p=qは，((p→q)∧(q→p))と同値
³ p→q=￢p∨q
2.
二重否定，ド・モルガンの定理を適用する．
³ ￢（￢ｐ）=ｐ
³ ￢(p∧q)=￢p∨￢q，
￢(p∨q)=￢p∧￢q
3.
分配律を適用する．
³ p∨(q∧r)=(p∨q)∧(p∨r)，
³ p ∧(q ∨r)=(p ∧q) ∨(p ∧r)
例P = Q ∨R
演習2 節形式
² 次の命題論理式を連言標準形の節形式に変
換しなさい．
³ （p→q）∧（￢p→￢（q∨r））
述語論理
² 命題の中に変数を用いて，変数の値によって
真・偽を捉える記号論理
² 命題論理では扱えない例
³ すべての人は平和を好む
³ 太郎は人である．→ 太郎は平和を好む．
² 述語論理は命題に含まれる変数に着目
² その命題における変数の性質や状態を述語
(predicate)を用いて推論
述語論理式の記号と定義
述語論理はある事実を記述することができる
定数記号
関数記号
述語記号
論理記号
限量記号
変数記号
述語論理式の要素
項の定義
² 定数記号，変数記号はすべて項である．
² t1, t2, . . . , tn が項であり，f が関数記号であるとき
f(t1, t2, . . . , tn)も項である．
素式の定義
! t1, t2, . . . , tn が項であり，Pが述語記号であるとき，P(t1, 
t2, . . . , tn)を素式(atomic formula) という．
述語論理式の定義
² 素式は論理式である．
² P,Qが論理式であれば，論理記号を用いて構成される
￢P（否定）, P ∧Q（連言）, P ∨Q（選言）, P → Q（含
意）, P = Q（同値）も論理式である．
² P が論理式で，x が個体変数であるとき，∀x P, ∃x P 
は論理式である．
² 上記より論理式となるものだけが論理式である．
限量記号の注意
² 限量記号の作用域
21
∀x ∃y [(P(f(x),w)∨Q(y,z)) →∃x ∀z R(x,y,z)]
² 限量記号の順序
(1)∀x ∃y P(x,y)        (2) ∃y ∀x P(x,y)
a
b
c
d
a
b
c
d
x        P        y
a
b
c
d
a
b
c
d
x        P        y
限量記号の同値関係
² ∃x P（x）= ∃y P（y）
∀x P（x）= ∀y P（y）
² ￢∃x P（x）= ∀x[￢P（x）]
￢∀x P（x）= ∃x[￢P（x）]
² 論理式Qが個体変数xを含まない時
∀x [P(x)∧Q]=∀x P(x)∧Q
∀x [P(x)∨Q]=∀x P(x)∨Q
∃x [P(x)∧Q]= ∃x P(x)∧Q
∃x [P(x)∨Q]= ∃x P(x)∨Q
² ∀x [P(x)∧Q(x)]= ∀x P(x)∧∀x Q(x)
∃x [P(x)∨Q(x)]= ∃x P(x)∨∃x Q(x)
22
述語論理式の例
² 私は本を持っている
² 私は本かノートを持っている
² すべての女子はケーキが好きだ
² 誰も自分の背中をさわれない
² ペンギン以外の鳥は飛ぶ
23
演習3 述語論理式
1.
すべての人は平和を好む
2.
太郎は平和を好む
3.
兄弟姉妹
（同じ両親から生まれた（同一人物ではない）子供）
をそれぞれ，述語論理式であらわしなさい．
※以下の関数記号、述語記号を使ってください。
³ 人: human(x), 好む: like(x,y), 平和: peace(x)
³ yはxの親である: parent(y,x)
述語論理のスコーレム標準形への変形
² スコーレム標準形
³ スコーレム関数を用いて存在記号∃を除去した節
形式なので，スコーレム標準形と言われる．
スコーレム標準形への変形例
1.
同値と含意の除去
2.
二重否定の除去とド・モルガンの法則による
否定記号の移動
￢(∀x p(x)) = ∃x(￢p(x)) 
￢(∃x p(x)) = ∀x(￢p(x)) 
限量記号のド・モルガンの法則
3.
変数の標準化
4.
スコーレム関数を用いた存在記号の除去
5.
冠頭形への変形
6.
分配律を用いて節形式へ変形
7.
各節の変数の独立化
⇒
節集合
®スコーレム標準形による節形式
®∀x1,.... ,∀xn (C1∧C2 .... ∧Cn)
®節形式での記述
C={C1, C2 ,.... , Cn}
母式（matrix）
演習4
² 次の述語論理式のスコーレム標準形を求め，
節集合形式で表しなさい．
∀x(P(x)→∃y(Q(x,y)∧R(x)))
まとめ
² 命題論理式
² 述語論理式
³ 事実を表す一般的な自然文を述語論理式として
表現する方法
² 命題論理式の節形式への変形方法
² 述語論理式のスコーレム標準形および節集
合形式への変形方法
人工知能
導出原理
東京農工大学工学部知能情報システム工学科
藤田桂英
(katfuji@cc.tuat.ac.jp)
1
内容
² 導出原理
² 導出制御戦略
² 一般疑問文への質疑応答
² 特殊疑問文への質疑応答
2
恒真式，恒偽式
² 素式の真偽にかかわらず，常に真であるも
のや常に偽であるもの
³ 恒真式(tautology): 解釈によらず真=妥当
³ 恒偽式(contradiction): 解釈によらず偽=矛盾
³ 充足可能(satisfiable): 解釈次第で真
³ 充足不能(unsatistiable): 解釈によらず偽
同じ
恒真式
恒偽式
論理式
充足可能
充足不能
恒偽式(ｺﾝﾄﾗﾃﾞｨｸｼｮﾝ)と恒真式(ﾄｰﾄﾛｼﾞｰ)
² 「僕は君を愛してもおり，愛していなくもある．」
² 「世の中には二種類の人間がいる．猫を愛する
ものと，猫を愛さないものだ．
恒偽式：p∧￢p
恒真式：p∨￢p
矛盾して意味不明
あたりまえだから
何の情報もない
導出
² 節集合C= {C1, .... , Cn}における節Ci, Cj が，
あるリテラルPとその否定リテラル￢Pを含ん
でいた時，これら二つの節から新たな節を導
く推論形式を導出(resolution)という．
親節
導出節
三段論法と等価
導出原理
² 人手ではなく，アルゴリズムによって自動的に証明
Pが恒真式⇔￢Pが恒偽式: 矛盾がある．
前提X の節集合に，結論の否定￢Y を節として加えた節集合に
対して導出を繰り返すことで，空節を導けばよいことがわかる．
² 前提Xと結論Yに対して，X → Y (X ならばY)を証明
導出グラフの例
導出反駁木: 
空節を根に持つ導出グラフ
単一化置換
² 導出を行うために引数を同一のものにする
³ 変数は任意の値がとれる
² 定数+変数→定数
² 変数+変数→同じ変数
² 定数+定数→定数（同じ定数の場合）
² 複合項同士→それぞれの引数同士を単一化
一般の論理式から節への変換方法
² ￢(∀x f(x)) →∃x ￢f(x)
² ￢(∃x f(x)) →∀x ￢f(x)
² ∃x ｆ（x）→ｆ（ｃ）（定数）
² ∀x ｆ（x）→ｆ（x）（変数）
² ∃x∀y ｆ（x, y）→ｆ（ｃ,y）
² ∀y∃x ｆ（x,y）→ｆ（ｃ（y）,y）(スコーレム関数)
三段論法の証明
² 前提
A→B(aならばb) = ￢A∨B
B→C(bならばc) = ￢B∨C
² 結論
A→C(AならばC)= ￢A∨C
² 結論の否定
￢(A→C) = ￢(￢A∨C) = A ∧￢C
￢A∨B       ￢B∨C       ￢C           A
￢B
￢A
□
前提: Everyone loves someoneから
結論: 太郎と次郎は同じ人を好きであるを証明
² 前提の解釈１∀x∃y love(x,y)→love(x,a(x))
² 前提の解釈２∃y∀x love(x,y)→love(x,a)
² 結論の否定
￢[∃z (love(taro,z)∧love(jiro,z))]
＝∀z ￢love(taro,z)∨￢love(jiro,z)
￢love(taro,z)∨￢love(jiro,z)        love(x,a(x))
x=jiro, a(x)=z
￢love(taro,a(jiro))                           
前提の解釈1の場合
できない!
前提の解釈2の場合
￢love(taro,z)∨￢love(jiro,z)               love(x,a)
jiro=x, z=a
￢love(taro,a)
taro=x
□
導出制御戦略
² 親節内の特定の二つの節を具体的にどう
選んだら良いかが決まらない
どの順番で
各節をくっつける？
導出制御戦略
² 機械的な制御戦略
³ 幅優先戦略(breadth-first strategy)
³ 線形導出(linear resolution)
² 意味的な制御戦略
³ 支持集合戦略(set-of-support strategy)
³ 意味導出(semantic resolution)
基本的な探索
前提X
結論￢Y
間違っているとしたら結論
の可能性大→結論の
節から重点的に攻める．
演習1 導出原理
² 前提(P∧Q)→R, P→Q, P から結論Q∧Rが導
けることを，導出原理を用いて証明せよ．
質問応答システム
ゴジラは大きいですか？
YES
前提知識
- monster(x) → big(x)
- monster(ゴジラ)
一般疑問文に対する質問応答
² 一般疑問文
³ 「Do you～?」「Is this～?」→「はい」，「いいえ」
² 手法
³ (事前知識) → (疑問文中で問われている事実)という述語
論理式を構成
³ これが恒真式であることを導出
³ (monster(x) → big(x)) ∧monster(ゴジラ) → big(ゴジラ)
演習2 一般疑問文
² 「ネズミは動物だ」
² 「あらゆる動物は生き物だ」
² 「藤田は人間だ」
という知識を前提として
² 「ネズミは生き物か？」
という質問に対する回答を導出グラフを用いて求めよ．
² xは動物だ: animal(x)
² xは生き物だ: living(x)
² xは人間だ: human(x)
特殊疑問文に対する質問応答
² What, When, Where, Why, Who, How といった
5W1H を問われる疑問文
³ 「由美子さんは何の食べ物が好きですか？」⇒
「何かx が存在し，由美子さんはそのx が好き」
³ 前提知識like(由美子，イクラ) があったとすると，
←単一化
単一化を逆にたどれば由美子さんが
好きなのがイクラだとわかる．
演習3 特殊疑問文
² 「ネズミは動物だ」
² 「あらゆる動物は生き物だ」
² 「藤田は人間だ」
² 「あらゆる人間は動物だ」
という知識を前提として
² 「動物なのは誰か？」
という質問に対する回答を導出グラフを用いて
求めよ．
Prolog
² 導出原理を用いた定理証明や質問応答を行うプログ
ラミング言語→Prolog (PROgraming in LOGic) 
² Prolog は論理型プログラミング言語の一種である．
スフィンクスの問い
² 「貴子は洋子の娘」「子供の子供は孫」「娘ならば子供である」
「洋子は豪太郎の娘だ」「靖は洋子のいとこだ」
そしてスフィンクスは問う
² 「さて，豪太郎の孫は誰だ？」
1. 「貴子は洋子の娘」= 娘（貴子，洋子）
2. 「子供の子供は孫」= 子(y,x)∧子(z,y)→孫(z,x)
3. 「娘ならば子供である」= 娘(x,y)→子(x,y)
4. 「洋子は豪太郎の娘だ」= 娘(洋子，豪太郎)
5. 「靖は洋子のいとこだ」= いとこ（靖，洋子）
6. 「さて，豪太郎の孫は誰だ？」= ∃w 孫(w,豪太郎)
演習4 スフィンクスの問い
C1: 娘（貴子，洋子）
C2: ￢子(y,x)∨￢子(z,y)∨孫(z,x)
C3: ￢娘(x,y)∨子(x,y)
C4: 娘(洋子，豪太郎)
C5: いとこ（靖，洋子）
C6: ￢孫(w,豪太郎)
節集合形式
上記の節集合形式にもとづいて，
導出グラフを用いてスフィンクスの問いの答えを導け．
導出グラフによる証明
１．娘（貴子，洋子）
２．￢子(y,x)∨￢子(z,y)∨孫(z,x)
３．￢娘(x,y)∨子(x,y)
４．娘(洋子，豪太郎)
５．いとこ（靖，洋子）
６．￢孫(w,豪太郎)
支持集合戦略
￢子(y,豪太郎)∨￢子(w,y)
￢娘(y,豪太郎)∨￢娘(w,y)
￢娘(w,洋子)
□
(貴子/w)で単一化置換
(w/z),(豪太郎/x)で単一化置換
二回作用
単一化付き
(洋子/y)で単一化置換
まとめ
² 導出原理
³ アルゴリズムによって自動的に証明
³ 述語論理による質問応答システムを導出グラフ
により証明
² 導出原理に基づいた質問応答の実行事例
³ 一般疑問文
³ 特殊疑問文
人工知能第11回
Web インテリジェンス
東京農工大学工学部知能情報システム工学科
藤田桂英
(katfuji@cc.tuat.ac.jp)
1
内容
² Web検索の仕組み
³ 経済モデルとしてのWeb(SEO, 検索オークション）
³ 複雑ネットワーク解析
³ リンク解析（Page Rank, ハブなど）
2
参考書（情報検索，Web検索）
² Christopher D. Manning, Prabhakar Raghavan, 
Hinrich Schuetze “Introduction to Information 
Retrieval,” Cambridge University Press
² 徳永健伸, 辻井潤一，“言語と計算(5) 情報検索
と言語処理,” 東京大学出版会
² 北研二, 津田和彦, 獅々堀正幹，“情報検索アル
ゴリズム”  共立出版
3
Web (World Wide Web)とは?
² オープン(開放的)な情報共有のしくみ
³ インターネット上での情報公開と相互参照を可能にする
³ 原型は1989年にティム・バーナーズ・リーが考案
http://www.w3.org/People/Berners-Lee/ 
4
「インターネット」は,地球規模で物理的に
相互接続されたコンピュータ・ネットワーク
Webの基本技術
² URI (Unified Resource Identifier)
³ ネットワーク上の情報を一意に特定するアドレス指定方式
³ インターネット上での情報公開と相互参照を可能にする
² HTTP (HyperText Transfer Protocol)
³ コンピュータ同士が情報をやりとりする規約
² HTML (HyperText Markup Language)
³ ハードウェア環境によらずに情報を表現する文書記述言語
5
URIの意味
² http: データを伝達するのに使われるプロトコル
² www.tuat.ac.jp : ドメイン, ウェブページの階層のルート
² /department/index.html : ウェブサーバーが返す情報を
含んでいるファイルへの階層パス
³ index.htmlはハーパーリンクとコンテンツ、表示規則
6
http://www.tuat.ac.jp/department/index.html
² URI（Uniform Resource Identifier）
³ 名前または場所を識別する書き方のルールの総称
² URL（Uniform Resource Locator）
³ 場所を示す書き方のルール
² URN（Uniform Resource Name）
³ 名前を永続的に識別する書き方のルール
静的と動的なウェブページ
² 静的なウェブページ(static web page)
³ ページに対する１つのリクエストから次のリクエストまで
かわらないコンテンツ
² 動的なウェブページ（dynamic pages)
³ データベースのクエリに応じてアプリケーションサーバー
によって機械的に作られる
³ URLの中に“?” が含まれる
7
検索エンジン最適化
² 検索結果でより上位に現れるようにウェブページを
書き換えること(SEO)
³ 適切なキーワードをタイトルやページ先頭に持ってくる
³ リンクを増やす
³ HTML(title, strong)による最適化
³ 検索エンジンのランキングアルゴリズム
³ 検索エンジンスパム
® よく検索されるであろうキーワードを非表示で埋め込む
® 不適切なリンクや大量のリンク
² 検索エンジンに直接広告出稿して自社Webサイトへ
の訪問者数を増やすマーケティング手法（SEM）
8
検索連動型広告
² 検索連動型広告は商業的に大成功している
³ Google Inc. の2005年Total Revenue : 
$6.14 billion(6億ドル) ‒ 98%が広告収入による
³ Yahoo! Inc.の2005年Total Revenue : 
$5.26 billion(5億ドル) 
9
検索連動型広告オークション
² Overture (GoTo) : 革新的なネット広告ビジネスモデル
² ユーザが検索語(例えば“ハワイ”)を検索エンジンに入力
² 検索語(例えば“ハワイ”)に関する検索結果が表示される
³ 検索語に関連するページへのリンク
³ 検索語に関して関連するスポンサーのリンク
² 広告料金の決定
³ 広告主はユーザの広告がクリックされる率(Click Trough 
Rate)に応じてお金を支払う
² キーワードや1クリック単位をベースに広告を出せる
² キーワード単位なので、小規模な契約をたくさんできる
10
Generalized Second-price 
Auction (GSP) 
² 単純なオークションプロトコルだと不安定
² i 番目のポジションの広告主
³
(i+1番目のポジションの入札額)+(最小増加可能額)を支払う
² ゲーム的な要素が取り除かれ安定
³ 自分では支払額を操作することができない!
11
ハイパーリンクとアンカーテキスト
² アンカーテキストはリンク先の情報を示している？
³ アンカーテキストがハイパーリンク先の正確な情報を伝え
ていない場合がある
³ 東京農工大学は<a href= “http://www.tuat.ac.jp”>こちら</a>
² HTMLの構文解析は無意味？
³ イメージの中にテキストを埋め込んでいる
12
<a href= “http://www.tuat.ac.jp”>東京農工大学</a>
ハイパーリンク
アンカーテキスト
ウェブグラフ
13
Page A
hyperlink
Page B
Anchor
² 静的なHTMLページ: 点(ノード）
² ハイパーリンク: 矢印（エッジ）, 有向辺
³ アンカータグによって表現される
³ 入リンク(in-link): ページに入ってくるリンク
³ 出リンク(out-link): ページを出て行くリンク
² ウェブグラフ: 点と矢印の集合
ウェブグラフの例
² AからFまでラベル付けされた６つのウェブページ
² ページBは入次数(in-degree)が3、出次数(out-degree)が１
³ Webの世界では入次数は平均8-15本
² 強連結ではない: B-Fのどのページ数からもAに至る道はない
14
複雑ネットワーク
15
たくさんが関連して構成されるシステム
基本構成要素óノード(Node)
基本構成要素間の関連óリンク(Link)
ネットワーク(Network)
SNSやTwitterの友人関係
World Wide Web
都市間の交通網（高速道路，航空路線）
ネットワークの構造に共通する性質
1. すべてのノード間がつながれていない（非完全グラフ）
2. ノード間のリンクの存在にはランダム性がある（ランダム性）
3. 少数ではあるがたくさんのノードとリンクでつながれているノードが
存在する（ハブの存在）
「複雑ネットワークの例」
16
analog TV circuits
(テレビ内部の回路部品の結びつき）
17
複雑ネットワークのハブ
18
例：仙台からベネチアまで飛行機で移動したいとしたら
仙台
東京成田
ミラノ
ベネチア
札幌
新潟
ジェノバ
フィレンツェ
すぐ近くの空港間の航空便しかない
→乗り継ぎ回数大
すべての空港間で航空便
が運行→飛行機台数大
ハブ空港のおかげで
世界的距離が短くなる
（スモールワールド）
• ハブは多い必要はないが、ある程度の数は必要
• ネットワークに階層構造が生まれる
• ハブが壊れたら、ネットワーク構造が壊れる
中心性
² ネットワークではなく個々のノードに着目
³ 局所性の分析
² 次数中心性
³ 次数そのもの
² 近接中心性
² 媒介中心性
³ 他のノードにたどり着くために当該ノードを通らなけ
ればいけない割合
19
(ノードi 以外のノード数)
(ノードiとほかの全ての点との距離の総和)
複雑ネットワークの統計的性質
20
スモールワールド性
平均最短経路長l: ノード間を結ぶ最短経路の長さ
（最短経路長）のすべてのノード対についての平均
平均次数
次数ki：ノードi につながっているリンクの本数
N：ノードの総数, p(k): 次数Kのノードの割合
k
l
スケールフリー性
スモールワールド性はもつ
がスケールフリー性をもた
ない複雑ネットワーク
スモールワールド性とス
ケールフリー性を併せ持
つ複雑ネットワーク
ベキ乗則の性質
ハブのある
なしの違い
中間のわずかなノードを介して
接続される性質
ベキ乗則(power low)
² 入次数がiのウェブページの総数が1/iα に比例
³ 一般的なWebの世界ではα=2.1
21
ウェブページ数
入次数
ロングテール、80:20の法則
² ロングテール: グラフの黄色の部分
² Webページの総閲覧数の８割は、全Webページの２割が
算出している
³ SNSやTwitterでも同じような現象
² 商品売上の8割は、全商品銘柄のうちの2割で生み出す
² 成功例: Amazon, オンライン小売り店
22
ロングテール
↓
緑の面積: 黄色の面積= 80: 20
リンク解析おけるWeb検索の前提
1.
ページBを指しているアンカーテキストは
ページBのよい記述である
2.
AからBへのハイパーリンクは、ページAの
作成者によるページBの推薦を表す
例外) 内部リンク, リンク集など
23
PageRankのアイデア
² 多くの良質なページからリンクされているページは、
やはり良質なページである
² 利用者がページをリンクをたどってネットサーフィン
する状況を模擬
³ 良いページには沢山の利用者がいると考えればよい
³ ページの重みが決める
³ リンク元ページからの流入する重み総和がそのページの
重み
³ リンク先へ流入する重みは、そのページの重みをリンク先
の本数で割ったもの
24
PageRank Scoring
² ランダムウォークを仮定
³ ランダムにスタートページを選ぶ
³ AからAがリンクしているページにランダムに選んで遷移
= 等確率で選ぶ
² 何度も遷移すると、頻繁に訪れるページが出てくる
= 多くのリンクが入ってきているページ
² ランダムウォークで頻繁に訪れるページは重要
= PageRank
25
A
1/3
1/3
1/3
B
C
D
テレポート
² ウェブページが出次リンクを持っていない
= 次に訪問するページがなくなってしまう
1.
出リンクを持たないノードで、テレポート操作を呼ぶ
2.
出リンクを持つノードで確率10%でテレポートを呼び、
90%でランダムウォークする
²
できるだけ多くのページを訪問する
26
??
マルコフ連鎖(Markov chain)
² マルコフ連鎖はN個の状態(state)とN´Nの遷移確率行列
P (transition probability matrix)により特徴付けられる
³ P の各要素は0-1の値、各行の要素の和は１
² 任意の特定の時間ステップではN状態のうちの一つ
² Pijは状態がi にあるときにj にある確率を示す
27
N=3
C
A
B
0.5
1
1
0.5
マルコフ連鎖とウェブグラフ
² ウェブのランダムウォークをマルコフ連鎖とみなす
³ ウェブページ= 状態
³ 遷移確率= 他のウェブページに移動する確率
³ テレポートは遷移確率に依存
28
² テレポートとウェブページの遷移確率行列P
³ ステップ4, 5 を行う意味
= 外向きリンクが0のページにも概念的にリンクを与える
P' = (1−α)P +α
1
N
[ ]N×N
リンク先の中からランダムに選択
全webページからランダムに選択
（テレポート）
29
A
B
C
＜例題＞
左のウェブグラフの
遷移確率を計算する
（α = 0.5)
² ウェブページの確率遷移行列Pの作り方
1.
ページi からページj にリンクあり: Pij =1
2.
ページi からページj にリンクなし: Pij =0
3.
Pの各1をその行の１の総数でわる
4.
得られた行列を1-α倍する
5.
その結果の行列の各要素にα/Nを足し、Pを得る
30
0
1
0
1
0
1
0
1
0
!
"
#
#
#
$
%
&
&
&
リンクありに１、リンクなしに０
各１をその行の１の総数で割る
得られた行列を1-α倍する(α = 0.5)
0
1
0
1/ 2
0
1/ 2
0
1
0
!
"
#
#
#
$
%
&
&
&
0
1/ 2
0
1/ 4
0
1/ 4
0
1/ 2
0
!
"
#
#
#
$
%
&
&
&
各要素にα/Nを足す(N=3)
0
1/ 2
0
1/ 4
0
1/ 4
0
1/ 2
0
!
"
#
#
#
$
%
&
&
&
+
1
2×3
1 1 1
1 1 1
1 1 1
!
"
#
#
#
$
%
&
&
&
1/ 6
2 / 3
1/ 6
5 /12
1/ 6
5 /12
1/ 6
2 / 3
1/ 6
!
"
#
#
#
$
%
&
&
&
エルゴード的マルコフ過程
マルコフ連鎖は、ある正整数T0があり、マルコフ連鎖のす
べてのi, j に対して、もし時刻０に状態i からスタートし、
すべてのt > T0 に対して、時刻t に状態j にいる確率が０
より大きければ、エルゴード的と言われる
31
既約性(irreducibility)
任意の状態から他の任意の状態への遷移列で確率が
正のものであることが保証
非周期性（aperiodicity)
状態が複数の集合に分かれて、すべての状態遷移が
周期的に一つの集合からもう一つの集合にいくようなことがない
エルゴード的マルコフ連鎖と安定状態
32
任意のエルゴード的なマルコフ連鎖に対して、唯一の安定
状態の確率ベクトル
が存在し、それはP の主左側固有ベ
クトルであり、もし
がt ステップ内で状態i に訪問する
数とすると
!
π
η(i,t)
lim
t→∞
η(i,t)
t
= π(i)
である。ここで
は状態i の安定状態確率である
π(i) > 0
〔テレポート付きのランダムウォーク〕
マルコフ連鎖の状態上の唯一の安定状態確率分布
= PageRank
PageRankの計算
33
²
: 全ページの重要度を表すベクトル
² P: 遷移確率行列
1.
を計算
2.
を計算する
3.
diff が一定値以下になり収束するまで繰り返す
®
固有ベクトルが求まるまで計算
!
xi
!
xi+1 = !
xiP
diff (!
xi+1, !
xi) = !
xi+1 −!
xi
＜例題＞
スライド１４の確率遷移行列の
安定状態確率分布（=Page Rank)をもとめる
34
（初期ベクトルの決定）
PageRankの活用
² d2, d3, d4, d6は少なくとも二つの入リンクを持っている
² d2 は２つの入リンクを持っているのにPageRankは低い
³ d3に出て行ってしまう
² d6 のPageRankは最大値
³ 出て行く先がない
35
遷移確率行列
PageRank
*リンクのアンカーテキストに出現する語が
リンクのタグとなっている
特定話題のPageRank
² 特定話題のPageRankを計算する
³ スポーツ関するPage Rank、政治に関するPageRank
³ パーソナライズしたPageRankを計算できる
36
•
60%がスポーツに、40%が政治に
興味を持っているユーザを仮定
•
テレポート確率が10%ならば、
スポーツのページに6%、政治の
ページに4%移動する
HITSのアイデア
² 探し当てたいWebページは必ずしも検索のキー
ワードを含まない
³ TOYOTAやHONDAのページに自動車製造の
キーワードは見当たらない
³ Yahoo !などの権威あるページは検索キーワードを含む
² キーワードではなくWebのリンク構造を利用
(PageRankと同じ意図)
² HITSは、ある話題に対するauthorityとhubとの
関係を使う
37
Hyperlink-Induced Topic Search 
(HITS)
² クエリが与えられたとき、各ウェブページに二つのスコ
アを割り当てる:
³ Authority: ある話題に対して権威ある情報を提供する
® 白血病→ 国立癌研究所
³ Hub: 多くのノードと繋がりがあるノード
® リンク集（権威あるページをリンクしているとは限らない）
u 真のauthority とhub は相互に強化する
u Good hub pages points to many good authority pages
u Good authority pages are pointed to by many hubs.
Sec. 21.3
HubとAuthorityのイメージ
                                                    AT&T        
 Alice                     
 
                                  ITIM  
Bob 
                                  O2 
携帯電話会社（USA）
Hubs
Authorities
Sec. 21.3
Root set とBase set
² Root set 
³ あるテキストクエリを含む全ウェブページ
² Base set
³ Root set内のウェブページがリンクしているページ
³ Root set内のウェブページをリンクしているページ
Sec. 21.3
Root
set
Base set
hubとauthorityを発見する
² hub score h(x) とauthority score a(x) を“base set”をす
べてのウェブページx に対して計算
1.
初期化: for all x, h(x)¬1; a(x) ¬1;
2.
Iteratively update all h(x), a(x); （次のスライド）
3.
繰り返し終了後
³ Top Hubs: hub score h(x) が高い値のページ
³ Top authorities: authority score a(x) が高い値のページ
Sec. 21.3
Iteratively update
² 以下の更新を繰り返す
³ ５回程度繰り返せば収束する場合が多い
for all x:
x
x
Sec. 21.3
↑ yがxをリンクしている
ウェブグラフの隣接行列
² N´N 隣接行列A:
³ N個の各ページが列、行に対応している
³ ページiからページjへのリンクがある: Aij = 1
ページiからページjへのリンクがない：Aij = 0.
1
2
3
1      2      3
1
2
3
0      1      0
1      1      1
1      0      0
Sec. 21.3
行列・ベクトルの場合
AT はAの転置行列
Sec. 21.3
← AAT固有ベクトルの式
（固有値の式）
← ATA固有ベクトルの式
HITSの計算
1.
目標となるWebページの部分集合を構成し
て、隣接行列Aを作りAATとATAを計算
2.
AATとATAの主固有ベクトルを計算し、Hub 
scoreとAuthority score（,   )を計算
³
ベキ乗法や線形行列を使って計算可能
3.
上位スコアを持つハブと権威者を出力
45
,
HITSの活用
² d3が権威者
² 二つのハブ（d2, d6 )はjaguarのリンクにより権威者を示す
² HITSにより別の検索クエリに関連する単語を発見できる
³ 白血病と骨髄移植など
46
隣接行列
*リンクのアンカーテキストに出現する語が
リンクのタグとなっている
まとめ
² Web検索の仕組み
³ Webの基本技術
² 経済モデルとしてのWeb
³ SEO
³ 検索オークション
² 複雑ネットワーク
³ ハブと中心性
³ ロングテール
² リンク解析
³ Page Rank
³ HITS
47
人工知能
マルチエージェントシステム(1)
~概論, 協調エージェント~
東京農工大学工学部知能情報システム工学科
藤田桂英
(katfuji@cc.tuat.ac.jp)
期末テストについて
² 対面のみ実施
² 日時：7月29日(月)，10:30 – 12:00
² 場所：L0026
² 範囲：人工知能の講義内容全て
² 注意事項
1.
所定の席に着席すること（SIRIUS座席表を配布）．
2.
学生証を机の上におくこと．
3.
講義資料，印刷したメモ，教科書，参考書のみ持ち込み可能
4.
スマートフォン，PC等の通信機能のあるものは持ち込み不可
5.
携帯電話，スマートフォン，はマナーモードにして，カバンに入れて
おいてください．時計の代わりとして使うことはできない．
6.
30分以上の遅刻は認めない．
7.
試験開始後30分間は退出を認めない
2
内容
² エージェントとは？マルチエージェントとは？
² 協調エージェント
³ 分散人工知能
³ 現実世界の実装方法に焦点
² 非協調エージェント
³ 経済学に基づくアプローチ
® エージェントは効用を最大化する
® ゲーム理論、オークション
³ 理論的なプロトコルの設計・形式化に焦点 
3
マルチエージェントシステムの基礎を概観
内容
² エージェントとは？マルチエージェントとは？
² 協調エージェント
³ 分散人工知能
³ 現実世界の実装方法に焦点
² 非協調エージェント
³ 経済学に基づくアプローチ
® エージェントは効用を最大化する
® ゲーム理論、オークション
³ 理論的なプロトコルの設計・形式化に焦点 
4
マルチエージェントシステムの基礎を概観
参考書
² 石田亨,片桐恭弘,桑原和宏著, “並列処理シリー
ズ11 分散人工知能,” コロナ社
² Gerhard Weiss, “Multi-agent Systems: A 
Modern Approach to Distributed Artificial 
Intelligence,” MIT Press
² Stuart Russell, Peter Norvig, “Artificial 
Intelligence: A Modern Approach,” Prentice 
Hall 
5
知的エージェント
² 自律的に行動する知的な主体
³ 例えば: 人間，ロボット，ソフトウェア，企業等
² 知的エージェントをロボットと考えると…
³ センサ：カメラ，赤外線センサー
³ アクチュエーター：モーター
エージェント
環
境
行為
知覚
？
センサ
アクチュエーター
6
知的エージェントに関する議論
² ある環境において自律的かつ合理的に目的をもって
判断し行動する(ことを目指した)プログラムやシステム 
² 歴史 
³ 人工知能 1970年代~2000年くらい 
³ 分散人工知能 
³ マルチエージェントシステム 
² アプローチ
³ 数値的アプローチ
³ 記号的アプローチ 
7
合理的エージェント
(Rational Agent)
² 最高の結果を達成するために行動する主体 
² 単純な“プログラム”と異なる点
³ 自律動作
³ 環境認識
³ 長期の持続性
³ 変化への対応
³ 他者の目標代行
² 合理的エージェントの利点
³ 論理学的アプローチより一般的
® 正しい推論はいくつかの合理的なメカニズムの一つ
³ 人間模倣型のアプローチより科学技術の発展に適応可能
® 環境が変わっても適応できる
8
マルチエージェントシステム
² 非集中型
³ 個人的合理性を持つエージェント
³ プライバシー
³ 実世界システムの自然なモデル
³ スケールアップが容易
³ 頑健性、信頼性、開発・管理が容易 
複数のエージェントが集まって、
共通／分散された問題を解くためのシステム
自律分散系
ロボットが協調してタスクを行う
9
災害シミュレーション（ロボカップレスキュー）
² 地震災害の避難状況をシミュレーション
² エージェント：消防隊，救急隊，啓開隊（瓦礫駆除）
² できるだけ多くの市民を救出する
10
ロボカップサッカー
² ロボットがサッカーを行う
³ シミュレーションリーグ
³ 小型、中型、ヒューマノイドリーグ
ロボットリーグ
シミュレーションリーグ
11
協調と非協調
² 協調エージェント(Cooperative Agent)
³ 分散人工知能
³ エージェントは本質的には協調的である
® エージェントは協調するための機構を持つ 
³ 現実世界の実装方法に焦点
² 非協調エージェント(Non-cooperative Agent)
³ 経済学に基づくアプローチ
® エージェントは効用を最大化する
(Utility Maximization, Self Interest)
® ゲーム理論、オークション
³ 理論的なプロトコルの設計・形式化に焦点 
12
協調的エージェントに関するトピック
² 古典的手法
³ 契約ネット
³ 黒板モデル 
² 比較的近年の手法 
³ Middle Agents 
³ Distributed Constraint Satisfaction Problem 
³ Team 
³ Distributed Coalition Formation 
³ etc. 
13
協調的エージェントに関するトピック
² 古典的手法
³ 契約ネット
³ 黒板モデル 
² 比較的近年の手法 
³ Middle Agents 
³ Distributed Constraint Satisfaction Problem 
³ Team 
³ Distributed Coalition Formation 
³ etc. 
14
契約ネットプロトコル 
(CNP: Contract Net Protocol) 
² 伝統的なタスク/資源割り当て手法
³ 分散センシング(位置がタスク)
³ 分散会議スケジューリング(空いた時間が資源) 
² エージェントの役割
³ マネージャーor 契約者 
² プロセス
³ タスクアナウンスメント、入札、落札 
² 相互選択 
³ 複数のマネージャーや契約者が存在可能 
³ マネージャーは複数の入札から最も高価値な契約者を選択 
³ 契約者は複数のアナウンスから最も高価値なタスクを選択
15
CNP: 基本モデル
² エージェント間の交渉によるタスク割当
² エージェントの役割
³ マネージャー: 契約の提案（複数）
³ 契約者: 契約の請負（複数）
³ 契約ごとに役割を決定
² 双方向のやり取り
³ タスクアナウンスメント: マネージャー→契約者
³ 入札:契約者→マネージャー
³ 落札:マネージャー→契約者
16
CNP: タスクアナウンスメント
17
CNP: 入札
² 各契約者がマネージャーを選択
18
CNP: 落札
² 各マネージャーが契約者を選択
19
CNP: 相互選択
² 契約者
³ タスクアナウンスメントを行うマネージャーは多数存在
® マネージャーは全契約者に対してタスクをアナウンス
³ 数多くのタスクの中から「入札」するタスクを独自価値
基準で選択
² マネージャー
³ 入札する契約者は多数存在
³ 数多くの入札から「落札」する契約者を独自の価値
基準で選択
20
CNP: 例外処理
² 契約が成立しない場合
³ すべてのエージェントがタスクを処理中
³ 告知されたタスクがエージェントにとって魅力がない
³ 入札資格がある契約者が存在しない
² 拒絶理由の記述
21
黒板モデル
² エージェントは一つのメモリを共有する
³ 単なる共有メモリとは異なる
² エージェントの処理
³ メモリからデータを読む
³ データを元に推論処理を行う
³ その結果(仮説)を機会主義的に書き込む 
² 黒板に書いてあることが必ずしも真でなくても良い
² 機会主義的問題解決 
³ 明示的な手続きがなくても、全体として問題を解決できる 
22
Hearsay-II
² 音声対話認識システム
³ データべースの検索文を作成
³ 話し手: 音声入力波形データの多様性と雑音
³ 聞き手: 文法の曖昧さや同音異義語
23
契約ネットプロトコルと黒板モデル
² 契約ネットプロトコル
³ タスク共有
³ エージェントはタスクを交換する
² 黒板モデル
³ 結果共有
³ エージェントは結果を交換する
24
協調的エージェントに関するトピック
² 古典的手法
³ 契約ネット
³ 黒板モデル 
² 比較的近年の手法 
³ Middle Agents 
³ Distributed Constraint Satisfaction Problem 
³ Team 
³ Distributed Coalition Formation 
³ etc. 
25
ミドルエージェント（Middle Agent)
² インターネット上に散在する非同形な
(Heterogeneous) エージェントを対象とする 
³ 異なる設計者が作ったエージェント 
² ユーザが希望するサービスを提供するエージェントを
見つけるには? 
³ 特定の遺伝子DBにアクセスできるエージェントを探す
³ MacBookを売っているエージェントを見つけるには? 
² ミドルエージェント(仲介エージェント)
³ マッチメーカ方式
³ ブローカ方式 
² Webサービスとして実現 
26
マッチメーカ
27
ブローカ
28
マッチメーカとブローカの比較
² マッチメーカ
³ 長所: 通信のボトルネックを避けられる
³ 短所:マッチーメーカはサービス提供エージェントが突然故障
すると対処できない
² ブローカ
² 長所: サービス提供エージェントが突然故障しても対処できる
² 短所: 通信のボトルネックになりうる
² ハイブリッド
³ マッチメーカ+ブローカ
³ ブローカがマッチメーカに対して、サービス提供エージェントの
ように振る舞う
29
分散制約充足問題
(Distributed CSP)
² 分散制約充足問題
³ 分散問題解決を制約充足問題の枠組みを用いて
形式化したもの 
² CSP(制約充足問題) 
³ 変数(variable) : X1, X2, X3, ... , Xn
³ 制約(constraint) : C1, C2, C3, ... , Cm
³ ドメイン(domain) : Di
® 変数Xi の持つ可能な値の集合
³ 問題の状態
® 例: {X1 = a, X2 = b, X3 = c,....}
30
色の塗り分け問題（制約充足問題）
31
Z
Y
X
{Yellow}
{Red, Yellow}
{Red, Yellow, Green}
•
Solution 1:  [X=Red, Y=Yellow, Z=Yellow]
•
Solution 2:  [X=Green, Y=Red, Z=Yellow]
•
Solution 3:  [X=Green, Y=Yellow, Z=Yellow]
違う色で塗る
Czx= {(Yellow, Red), 
(Yellow, Green)}
違う色で塗る
Cxy= {(Red, Yellow), (Yellow, Red),  
(Green, Yellow), (Green, Red)}
色の塗り分け問題（分散制約充足問題）
32
• 変数と制約が初期状態でエージェント間に分散されている
Z
Y
X
{Yellow}
{Red, Yellow}
{Red, Yellow, Green}
違う色で塗る
違う色で塗る
Agent A
Agent B
Agent C
非同期バックトラッキング
1.
各エージェントは自分の解を局所的に求める
2.
自分より優先順位の低い近傍のエージェントに解を通知
³
優先順位: 識別子の辞書的順番
3.
メッセージを受けたエージェントは自分の解との無矛盾を
確認
³
矛盾が存在→ 自分の解を他の可能な解に置き換え、
その解を他のエージェントに知らせる
³
置き換えが不可能→ NOGOOD を優先順位の高い
エージェントに送る
4.
NOGOOD を受け取ったエージェント: 無矛盾性を確認
5.
NOGOOD が送れない状態: 解が存在しない
通信/制御のボトルネックがない、セキュリティ、完全性あり
33
チームワーク(Teamwork)
² 共通の目的を達成するためのメンバー間の協力
活動 (cooperative effort) 
³ 複雑・不確実な状況での柔軟の調整
³ 協調的な交渉
³ モニタリング、故障発見・診断 
² 課題
³ メンバーが予測に反して故障したり、逆によりよい状況
を発見する
³ メンバーが不確実な状況に陥る
³ 通信のコストがかかる 
34
STEAM
(Shell for TEAMwork)
² 明示的にチームプランを持つ
³ 柔軟・頑健なチームを実現 
³ 階層的に個人・サブチームのプランにわけられる
³ コミットメントを得たチームオペレータが共通の意図(=プラン)になる
² RoboCup Soccerや戦闘フィールドに応用
35
チームオペレータ
個人オペレータ
提携形成 （Coalition Formation）
² 例: 物流会社に関する問題 
³ 10,000個の花束を東京から名古屋へ移送したい 
³ トラック数台 or ヘリコプター1台and フォークトラックが使える 
² 提携の候補
提携A: トラックとフォークトラックの提携
提携B: ヘリコプターとフォークトラックの提携
²
提携の評価
³
輸送料と時間
®
ヘリコプターは高価 
®
制約と規則から輸送時間は同じ
³
道路が渋滞、倒壊したらどうする？
36
分散提携形成問題の定義
²
エージェント集合: N = {A1,A2,...,An} 
²
エージェントは、あるタスクを実行するための能力を持つ 
³ Aiは、能力Bi = (bi1,bi2,..bir)を持つ
® 例えば、bi1は、いくつかの荷物を運ぶ能力 
²
タスク集合: {t1,t2,...,tm} 
²
各タスクtj を達成するためにはいくつかの能力が必要 
³ Bj = (bj1,bj2,...,bjr) 
²
エージェントはタスクti を実行するために提携を形成する 
²
提携Cの能力べクトル 
³ Bc= Σ Ai∈C Bi ←能力べクトルの合計 
³ Bc = (bc1, bc2, ..., bcr) 
²
タスクtjを実現するためには、Bj = (bj1,bj2,...,bjr)が必要 
²
すべてのタスクに関して Bji < Bci がなりたてば、タスクtjを実現可能 
37
分散提携アルゴリズム
1.
提携値を計算する
³ 各エージェントは、自分がメンバーとなる提携を作成する
³ 関係する他のエージェントの能力べクトルを得る
³ 各提携で実行可能なタスクをチェックする
³ 各提携値を計算する 
2.
望ましい提携を形成する 
³ 各エージェントは最も提携値の大きい提携を選択する 
³ 各エージェントは最良の提携を全エージェントにアナウンス 
³ 全エージェントの中で最良の提携から形成されていく
（エージェントが提携にアサインされていく）
³ 全エージェントが提携にアサインされるor 全タスクが達成可能な
提携が形成されるまで、繰り返す 
38
まとめ
² エージェントとは？マルチエージェントとは？
² 協調エージェント（分散人工知能）
³ 現実世界の実装方法に焦点
³ 契約ネット
³ 黒板モデル 
³ Middle Agents 
³ Distributed Constraint Satisfaction Problem
³ Team 
³ Distributed Coalition Formation 
39
人工知能
マルチエージェントシステム(2)
~非協調エージェント、オークション~
東京農工大学工学部知能情報システム工学科
藤田桂英
(katfuji@cc.tuat.ac.jp)
期末テストについて
² 対面のみ実施
² 日時：7月29日(月)，10:30 – 12:00
² 場所：L0026
² 範囲：人工知能の講義内容全て
² 注意事項
1.
所定の席に着席すること（SIRIUS座席表を配布）．
2.
学生証を机の上におくこと．
3.
講義資料，印刷したメモ，教科書，参考書のみ持ち込み可能
4.
スマートフォン，PC等の通信機能のあるものは持ち込み不可
5.
携帯電話，スマートフォン，はマナーモードにして，カバンに入れて
おいてください．時計の代わりとして使うことはできない．
6.
30分以上の遅刻は認めない．
7.
試験開始後30分間は退出を認めない
2
内容
² エージェントとは？マルチエージェントとは？
² 協調エージェント
³ 分散人工知能
³ 現実世界の実装方法に焦点
² 非協調エージェント
³ 経済学に基づくアプローチ
® エージェントは、効用を最大化する
® ゲーム理論、オークション
³ 理論的なプロトコルの設計・形式化に焦点 
3
マルチエージェントシステムの基礎を概観
合理的エージェント
² 自律的に行動する知的な主体
³ 例えば: 人間，ロボット，ソフトウェア，企業等
² 合理的エージェントは自身の効用（利得）を最大化できる
行動をとる = 期待効用最大化
エージェント
環
境
行為
知覚
？
センサ
アクチュエーター
4
利得関数
（効用関数）
内容
² エージェントとは？マルチエージェントとは？
² 協調エージェント
³ 分散人工知能
³ 現実世界の実装方法に焦点
² 非協調エージェント
³ 経済学に基づくアプローチ
® エージェントは、効用を最大化する
® ゲーム理論、オークション
³ 理論的なプロトコルの設計・形式化に焦点 
5
マルチエージェントシステムの基礎を概観
ゲーム理論概論
6
エージェントとゲーム理論
² ゲーム理論
³ 複数の意思決定主体による社会的諸問題を明確
に説明するための理論 
³ ミクロ経済学の一分野
² 合理的エージェント
³ どのような状況でも合理的に行動する主体
³ 相手が不確実性な状況でも合理的な行動をする
7
囚人のジレンマ
² ある重大事件に関して共犯であることがほぼ確実な二
人の容疑者AとBが、軽微な別件で捕らえられている 
² AとBは互いに接触し、話し合いする方法がない
² 自白か黙秘か選択できる
³ 一方が自白、一方が黙秘なら
→ 自白した方は懲役半年、黙秘した方は懲役10年 
³ 両方が黙秘なら
→軽微な罪で、両方懲役2年 
³ 両方が自白なら
→ 重罪が確定し、両方懲役５年
8
利得行列
黙秘
自白
黙秘
8, 8
0, 9.5
自白
9.5, 0
5, 5
9
容疑者A
容疑者B
２年, ２年
５年, ５年
10年, 半年
半年, 10年
全体として見ると
10
黙秘
自白
黙秘
8, 8
0, 9.5
自白
9.5, 0
5, 5
10
容疑者A
容疑者B
２年, ２年
５年, ５年
10年, 半年
半年, 10年
２人にとって一番良い
容疑者Aから見ると
11
黙秘
自白
黙秘
8, 8
0, 9.5
自白
9.5, 0
5, 5
11
容疑者A
容疑者B
２年, ２年
５年, ５年
10年, 半年
半年, 10年
<
<
相手が「黙秘」でも「自白」でも、自白の方が良い
容疑者Bから見ると
12
黙秘
自白
黙秘
8, 8
0, 9.5
自白
9.5, 0
5, 5
12
容疑者A
容疑者B
２年, ２年
５年, ５年
10年, 半年
半年, 10年
<
<
相手が「黙秘」でも「自白」でも、自白の方が良い
最終的には
13
黙秘
自白
黙秘
8, 8
0, 9.5
自白
9.5, 0
5, 5
容疑者A
容疑者B
２年, ２年
５年, ５年
10年, 半年
半年, 10年
結局２人とも「自白」
個人に取って最適な戦略を選んでいるの２人とも損をしている
= 囚人のジレンマ
支配戦略とナッシュ均衡
² 支配戦略
³ 相手がどのような選択肢を選んでも自分の取るべき
戦略が決まっているとき
² 最適反応戦略
³ 相手がある戦略をとったときに,その戦略のもとで
自分の利得を最大にするように行動する 
² ナッシュ均衡
³ 二人のとる戦略が互いに相手の戦略の最適反応
戦略になっている 
³ ナッシュ均衡のもとでは、どのプレイヤーも変更する
誘因をもたない
14
支配戦略均衡
² 支配戦略= 「自白」
² 支配戦略均衡= 両方とも「自白」
15
黙秘
自白
黙秘
8, 8
0, 9.5
自白
9.5, 0
5, 5
容疑者A
容疑者B
２年, ２年
５年, ５年
10年, 半年
半年, 10年
支配戦略均衡
<
<
ナッシュ均衡
16
² 最適反応戦略= A, B とも「自白」
→ ナッシュ均衡
16
黙秘
自白
黙秘
8, 8
0, 9.5
自白
9.5, 0
5, 5
容疑者A
容疑者B
２年, ２年
５年, ５年
10年, 半年
半年, 10年
ナッシュ均衡
<
<
パレート最適解
² パレート的改善:相手に迷惑をかけずに自分の
利得を高めること
³ [黙秘，黙秘]の方が [自白，自白]より利得が高い
³ 相手の利得を減らさない
² パレート最適解: パレート的改善が不可能な解
³ パレート最適解は社会として望ましい
³ ナッシュ均衡ではない場合、現実として実現が難しい
² 社会的余剰: 全プレイヤーの利得の和
17
18
囚人のジレンマでは？
黙秘
自白
黙秘
8, 8
0, 9.5
自白
9.5, 0
5, 5
容疑者A
容疑者B
２年, ２年
５年, ５年
10年, 半年
半年, 10年
社会的余剰最大
パレート最適
パレート最適
パレート最適
囚人のジレンマ（反復バージョン）
² AliceとBobが囚人のジレンマゲームを100回行う
³ AliceとBobは100回繰り返されることを知っている
19
? →  ?   → …  →   ?   →   ?   → (自白, 自白)
100回目
1回目
100回目の結果はそれ以降に影響なし→100回目に支配戦略を選ぶ
帰納的に考える
(100回目が決まれば、99回目はそれ以降に影響がない…）
(自白, 自白)→ (自白, 自白)   → … → (自白, 自白)
100回目
1回目
囚人のジレンマ（反復バージョン2）
² AliceとBobが囚人のジレンマゲームをN回行う
³ AliceとBobは何回繰り返されるか分からない
² シッペ返し戦略(tit-for-tat)
³ 黙秘で始まり、次以降は相手の行動を繰り返す
20
黙秘→  黙秘→ …  →   黙秘
→   黙秘→ 黙秘
N 回目
1回目
黙秘→  黙秘→ …  →   黙秘
→   黙秘→ 黙秘
N回目
1回目
Alice
Bob
・・・
演習1 囚人のジレンマ
以下の利得行列で表される囚人のジレンマの問題
において、パレート最適、ナッシュ均衡となる戦略
の組み合わせを求めなさい。
² 解答例: 容疑者A_黙秘、容疑者B_黙秘
21
黙秘
自白
黙秘
7, 7
6, 9.5
自白
0, 3
5, 5
容疑者A
容疑者B
オークション理論
（メカニズムデザイン）
26
マルチエージェントシステムと
オークション
² オークション
³ 何らかの財（資源）を最も良い購入条件を提示した
買い手に売却する
³ 各々の買い手が提示できる購入条件を競わせる
³ 効率的な資源分配方法
² マルチエージェントシステム
³ 合理的な主体同士の相互作用を使って問題を解決
するシステム
³ 複雑な問題を解決するために、システム全体として
最適なルールが必要がある
27
主なオークションの類型
² イギリス型オークション
³ 第一価格公開入札
² 第一価格秘密入札
³ 第一価格封緘入札
² オランダ型オークション
³ 競り下げオークション
² 第二価格秘密入札
³ ビックレーオークション
イギリス型オークション
² 第一価格競り上げ入札
² プロトコル
³ 入札値は公開
³ さらに高い金額に入札値を変更可
² 入札者の戦略
³ 自分の評価値，他者の評価値，
入札状況に依存
² 最善の戦略
³ 現時点の入札値から少額ずつ
競り上げる
³ 評価値に達したらおりる
900円
800円
入札者Aは900円まで払える
入札者Bは850円まで払える
A:800
B:810
A:820
A:840
B:830
A:860
B:850
落札額
オランダ型オークション
² プロトコル
³ 主催者が価格宣言し，
買い手がストップをかける
³ ストップをかけた入札者が
その入札値で落札
² 入札者の戦略
³ 自分の評価値，他者の
評価値の推定値に依存
² 最善の戦略
³ 一般には存在しない
主催者
1000円!
950円!
900円!
参加者
900円で買い!
スーパーの夕方の生鮮食品の値引きも、
ある意味では一種のオークション
第一価格秘密入札オークション
² プロトコル：
³ 他の入札者の入札値は知らない
³ 最も高い入札値をつけた入札者
がその値で落札
² 入札者の戦略
³ 自分の評価値，他者の評価値の
推定値に依存
² 最善の戦略
³ 一般には存在しない
入
札
箱
入札者A:900円
入札者B:850円
落札者はAで900円支払う
第一価格秘密入札オークション
32
第一価格秘密入札オークション
33
・申告した入札値が最大の買い手が入札
第一価格秘密入札オークション
34
入札者には虚偽の入札をする誘因が働く = 不安定 
第二価格秘密入札オークション
² 別名：Vickrey オークション
³ キーワードオークションで使われている
² プロトコル
³ 入札者は入札値を知らされず入札
³ 最も高い入札値をつけた入札者が二番目に
高い入札値で落札
² 最善の戦略
³ 自分の真の評価値で入札すること
入
札
箱
入札者A:900円
入札者B:850円
落札者はAで850円支払う
第二価格秘密入札オークション
² 最大の入札値を提示した入札者が財を得る(パレート最適)
² 勝者は二番目の値段を支払う(誘因両立) 
³ 真の値より高く申告する→ 第二価格が自分の真の値より高い場合、
勝ったとしても支払額は自分の真の値より高くなり損をする
³ 真の値より低く申告する→ 支払い額は同じ
36
誘因両立性
戦略的操作不可能性
² 第二価格入札(Vickrey) オークション 
³ 買い手は支払額を操作できない
→ 入札額を最大化するのが最善
³ 効用（利得）= 評価値- 支払額 
³ 全員の価値が最大化される割当を行う
® 一番高い入札をした人が落札する
真の申告をすることが支配戦略になる
Vickrey-Clarke-Groves (VCG) 
メカニズム 
² 各参加者は財のセットに関して評価値を申告
² 申告された評価値に基づいて，社会的余剰が最大
化されるように財が割り当てられる（勝者決定）
² 参加者は迷惑料を支払う
³ その参加者が入札に参加することによって生じる，
他の参加者の社会的余剰の減少分
² メカニズムは誘因両立
² 結果はパレート最適
組み合わせオークション
² 入札者はバンドルとして評価値を入札する
³ 複数種類の商品（財）が同時に販売される
³ 複数ユニット、複数オブジェクトの場合がある
² 組み合わせオークションの特長
³ 両方欲しい、一方だけが欲しいという入札が可能
³ 財の価値に依存関係があるとき入札しやすい
補完財と代替財
・買い手１にとって代替財
・両方買ってもあんまり嬉しくない
商品の組み合わせ＝{ご飯, 
パン,
(ご飯，パン)}
買い手1
500      
500     
600
買い手2       400   
600    
1000
• 買い手２にとって補完財
•
両方買わなければ価値は低いと考える
商品の組み合わせ＝{ご飯,     肉料理,     (ご飯, 肉料理)}
買い手1
300           200                   500
買い手2       200          200                   600
VCGの定式化
なるG*を計算する。
買い手の支払額は、
  
€ 
G* = arg
max
G=(G1,…,Gn )
vi(Gi)
i∈N
∑
G *~i = argmax
G\Gi
v j(G j)
N−i
∑
€ 
pi =
v j(G *~i
i≠j
∑
) −
v j(G*)
i≠j
∑
但し、
自分がいない場合の
全体の価値
実際の場合の
自分以外のプレイヤーの価値
VCGの具体例
財１
財２
（財１，財２）
入札者１
５
７
１２
入札者２
０
６
１０
入札者３
８
５
１３
VCGの具体例
² 社会的余剰が最大になる割当
³ 財１を入札者３に，財２を入札者１に割当
財１
財２
（財１，財２）
入札者１
５
７
１２
入札者２
０
６
１０
入札者３
８
５
１３
VCGの具体例
² 社会的余剰が最大になる割当
³ 財１を入札者３に，財２を入札者１に割当
² 支払額計算
³ 入札者１：１４ー８＝６
財１
財２
（財１，財２）
入札者１
５
７
１２
入札者２
０
６
１０
入札者３
８
５
１３
VCGの具体例
² 社会的余剰が最大になる割当
³ 財１を入札者３に，財２を入札者１に割当
² 支払額計算
³ 入札者１：１４ー８＝６
³ 入札者３：１２ー７＝５
財１
財２
（財１，財２）
入札者１
５
７
１２
入札者２
０
６
１０
入札者３
８
５
１３
VCGと誘因両立性
47
全体の幸せと個人の幸せが一致する 
入札者１がいない時の社会的余剰（14)
入札者１がいる場合の
他者の社会的余剰（8)
入札者１の評価値（7)
社会的余剰（15)
入札者１の支払額(6)
入札者１の効用
マルチエージェントシステムにおける
オークションの課題
² 勝者決定
³ NP困難問題
³ 勝者決定問題を効率/近似的に解決する手法が必要
² 価値決定
³ エージェントの評価値(価値)をどのように把握するか
² 戦略決定
³ エージェントの戦略をどのようにモデル化するか 
² 通信
³ 通信コストが多い
48
人工知能のまとめ
² 人工知能の導入
² 基本的な探索
² 最適経路探索（A*アルゴリズム, 最良優先探索）
² メタヒューリスティック探索（HC, SA, GA）
² ゲームの理論
² 確率と不確実性、確率的生成モデル
² 強化学習
² 記号論理と導出原理
² Webインテリジェンス
² エージェント
49
授業アンケート
² SIRIUSのトップページから
³ メニュー＞掲示・アンケート＞アンケート＞アンケート回答
³ 新着情報＞アンケートが登録されました。
50
